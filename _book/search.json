[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Latent Variable Modelling Workflow Reference",
    "section": "",
    "text": "Preface"
  },
  {
    "objectID": "index.html#what-is-this",
    "href": "index.html#what-is-this",
    "title": "Latent Variable Modelling Workflow Reference",
    "section": "What is this?",
    "text": "What is this?\nThis is a book full of code to use when you want to do latent variable modelling. It gives suggested workflows I’ve cobbled together from a few different textbooks, and has worked examples with data from those textbooks or from open datasets I found online. When you need to do latent variable modelling for your research, you can use these workflows as a place to start.\nSpecifically, it seems like these are the sub-areas of latent variable modelling to know how to do:\n\nExploratory Factor Analysis;\nConfirmatory Factor Analysis;\nItem Response Theory;\nFull SEM;\nLongitudinal SEM.\n\nMaybe I’ll discover some other types of things along the way. It’s a lifelong journey haha."
  },
  {
    "objectID": "index.html#what-am-i-referencing",
    "href": "index.html#what-am-i-referencing",
    "title": "Latent Variable Modelling Workflow Reference",
    "section": "What am I referencing?",
    "text": "What am I referencing?\nThe first book on latent variable modelling I read was Gorsuch (1983). This was a nice conceptual introduction, but the applied examples were pretty whack. I’ve since found a few sources with data and R code to work with:\n\nLatent Variable Modelling with R, by Finch (2015). They helpfully provide all of the datasets here.\nPrinciples and Practice of Structural Equation Modeling, by Kline (2011). The publisher provides data and code here.\nThe lavaan documentation has some nice worked examples too.\n\nI’ll mostly be using lavaan and tidyverse, but maybe also some brms at some point.\n\n\n\n\nFinch, French, W. Holmes. 2015. Latent Variable Modeling with r.\n\n\nGorsuch, Richard L. 1983. Factor Analysis, 2nd Edition.\n\n\nKline, Rex B. 2011. Principles and Practice of Structural Equation Modeling."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "cfa.html#getting-started",
    "href": "cfa.html#getting-started",
    "title": "2  CFA",
    "section": "2.1 Getting started",
    "text": "2.1 Getting started\nLet’s load the packages we’ll need for what is to come in this chapter:\n\nlibrary(tidyverse)\nlibrary(lavaan)"
  },
  {
    "objectID": "cfa.html#example-1-toxic-striving-energy",
    "href": "cfa.html#example-1-toxic-striving-energy",
    "title": "2  CFA",
    "section": "2.2 Example 1: Toxic Striving Energy",
    "text": "2.2 Example 1: Toxic Striving Energy\nThe first example we’ll look at is from Finch (2015). chapter 3. The practice dataset is introduced on page 10. It is from a study about human motivation. The dataset is a weird questionnaire called the ‘Achievement Goal Scale’ (AGS), which asks people 12 questions about how much toxic striving energy they have. The dataset provided seems to have lots of mysterious columns in it, but we’re probably good to just keep the columns with responses to the AGS questionnaire:\n\n### Load the data\ndat_raw <- foreign::read.spss('data/finch-and-french/edps744.sav') \n  \n### Clean the data\ndat_ags <- dat_raw %>% \n\n  # Convert to a data frame for ease of use\n  as.data.frame() %>% \n  \n  # Keep only columns that start with the prefix 'ags' followed by a question number\n  select(matches(\"ags\\\\d\")) \n\n\n2.2.1 Data Exploration\nWe don’t want to do too much exploration before fitting our factor models, because the whole game of CFA is to commit to our hypotheses before checking what the data looks like, so we don’t mislead ourselves with forking paths. But just for fun, we can explore the distributions of the answers to each of the 12 questions:\n\ndat_ags %>% \n\n  # Pivot to prepare the data for visualization\n  pivot_longer(\n    cols      = everything(),\n    names_to  = \"question\",\n    values_to = \"response\",\n    names_transform = list(question = fct_inorder)  \n  ) %>% \n\n  # Plot\n  ggplot() +\n  geom_histogram(aes(x = response)) + \n  theme_bw() + \n  facet_wrap(~question)\n\n\n\n\nSeems like some questions have different means and variances from each other. For example, the answers to ags11 and ags12 are relatively flat, while the answers to ags4 and ags5 are more bunched up around the highest values. The responses clearly skew towards higher values in aggregate.\nWe can also do some healthy exploration of missingness in the dataset. For starters: what proportion of values are missing in each row?\n\ndat_ags %>% \n  \n  # Calculate the proportion of missing values \n  summarise_all(~ sum(is.na(.)) / (sum(is.na(.) + sum(!is.na(.))))) %>% \n  \n  # Rounding to make the results more presentable\n  mutate(across(everything(), round, 6)) %>% \n  \n  # Create the table\n  knitr::kable(title = \"Proportion of Missing Responses in Each Column\") \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nags1\nags2\nags3\nags4\nags5\nags6\nags7\nags8\nags9\nags10\nags11\nags12\n\n\n\n\n1.1e-05\n5e-06\n5e-06\n1.6e-05\n1.6e-05\n1.1e-05\n1.6e-05\n1.6e-05\n1.1e-05\n2.2e-05\n1.1e-05\n1.6e-05\n\n\n\n\n\nThat’s very little missingness. Probably no need to do multiple imputation here.\nThe authors also do a preliminary test of whether the responses are normally distributed, since this is one of the fundamental assumptions of maximum likelihood estimation. Kristoffer Magnusson has created a cool interactive teaching tool that nicely illustrates this point. It is worth remembering that we do not make this type of assumption for linear regression in general – only for maximum likelihood estimates. All we need assume for linear regression is that the residuals are normally distributed, as opposed to the data themselves. This common misunderstanding leads to what Richard McElreath has called ‘histomancy’.\nTo evaluate the assumption of normalness underlying maximum likelihood estimation, the authors do what seems to be a multivariate version of a classic ‘normal probability plot’. These are explained nicely in this stack exchange thread. They also produce some of the classic tests of skew and kurtosis, which I don’t want to get into here. This youtuber has nice introductory videos about these topics.\n\n# Run the Mardia tests for normalness\nmardia.object <- psych::mardia(dat_ags)\n\n\n\n# Plot the multivariate version of the normal probability plot\nplot(mardia.object)\n\n# Present the outputs we're interested in\ntibble(\n  \"Skew\" = mardia.object$skew,\n  \"Skew p-value\" = mardia.object$p.skew,\n  \"Kurtosis\" = mardia.object$kurtosis,\n  \"Kurtosis p-value\" = mardia.object$p.kurt\n) %>% \n  \n  knitr::kable()\n\n\n\n\nSkew\nSkew p-value\nKurtosis\nKurtosis p-value\n\n\n\n\n2359.475\n0\n40.52999\n0\n\n\n\n\n\nThe plotted points don’t seem to fit the straight line super well, which suggests that the normalness assumption may not hold here. Also, the hypothesis tests for skew and kurtosis return some mighty low p-values, suggesting that we’ve got lots of each of them. So maybe maximum likelihood estimation isn’t such a good idea here?\nThe authors proceed with it anyway for pedogogical reasons, because they want to illustrate how the maximum likelihood estimates differ from estimates arrived at using other methods.\n\nIn actual practice, given the lack of multivariate normality that seems apparent in the previous results, we would likely not use ML and instead rely on the alternative estimation approach.\n\n\n\n2.2.2 Model Fitting\nThe researchers who collected the data do what good factor analysts do: they look to the literature to set up some clear and specific candidate hypotheses, and see the degree to which this new data is compatible with each of them.\nOne of the candidate hypotheses is that a person’s toxic striving energy (‘achievement goal orientedness’?) is secretly driven by four platonic unobservable things, namely:\n\nMastery Approach ‘MAP’ (eg. “I want to learn as much as possible”);\nMastery Avoidant ‘MAV’ (eg. “I want to avoid learning less than I possibly could”);\nPerformance Approach ‘PAP’ (eg. “I want to do well compared to other students”);\nPerformance Avoidant ‘PAV’ (eg. “It is important for me to avoid doing poorly compared to other students”)\n\nWe’ll call the above hypothesis H1. But there’s another hypothesis that says actually the ‘Mastery’ variables are just one monolithic thing, so really there are only 3 factors, namely ‘Mastery’, ‘PAP’, and ‘PAV’. We’ll call this one H2.\nThese will be the two candidate hypotheses we’re gonna test via factor analysis.\nThe way lavaan works is that you need to separately define the model syntax as a string, and then feed that string to one of the model-fitting functions like cfa() . Then we can call the summary() function to get a big table of outputs.\n\n# Define the relationships from my hypothesis\nh1.definition <- \n'map=~ags1+ags5+ags7\nmav=~ags2+ags6+ags12\npap=~ags3+ags9+ags11\npav=~ags4+ags8+ags10'\n\n# Fit the model\nh1.fit <- cfa(\n  data  = dat_ags,\n  model = h1.definition\n)\n\n# Look at the results\nsummary(h1.fit, fit.measures = TRUE)\n\nlavaan 0.6-12 ended normally after 48 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        30\n\n                                                  Used       Total\n  Number of observations                           419         432\n\nModel Test User Model:\n                                                      \n  Test statistic                               328.312\n  Degrees of freedom                                48\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              3382.805\n  Degrees of freedom                                66\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.915\n  Tucker-Lewis Index (TLI)                       0.884\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -7014.070\n  Loglikelihood unrestricted model (H1)      -6849.914\n                                                      \n  Akaike (AIC)                               14088.141\n  Bayesian (BIC)                             14209.277\n  Sample-size adjusted Bayesian (BIC)        14114.078\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.118\n  90 Percent confidence interval - lower         0.106\n  90 Percent confidence interval - upper         0.130\n  P-value RMSEA <= 0.05                          0.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.055\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  map =~                                              \n    ags1              1.000                           \n    ags5              0.774    0.057   13.564    0.000\n    ags7              1.100    0.064   17.263    0.000\n  mav =~                                              \n    ags2              1.000                           \n    ags6              0.974    0.078   12.523    0.000\n    ags12             1.039    0.096   10.805    0.000\n  pap =~                                              \n    ags3              1.000                           \n    ags9              0.853    0.038   22.349    0.000\n    ags11             1.103    0.052   21.178    0.000\n  pav =~                                              \n    ags4              1.000                           \n    ags8              1.599    0.084   19.091    0.000\n    ags10             1.525    0.073   20.861    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  map ~~                                              \n    mav               0.709    0.079    9.000    0.000\n    pap               0.066    0.060    1.093    0.274\n    pav               0.056    0.043    1.289    0.197\n  mav ~~                                              \n    pap               0.163    0.072    2.265    0.023\n    pav               0.178    0.053    3.355    0.001\n  pap ~~                                              \n    pav               1.143    0.102   11.236    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .ags1              0.562    0.047   11.951    0.000\n   .ags5              0.486    0.038   12.780    0.000\n   .ags7              0.211    0.032    6.602    0.000\n   .ags2              1.312    0.102   12.825    0.000\n   .ags6              0.469    0.049    9.537    0.000\n   .ags12             1.300    0.103   12.669    0.000\n   .ags3              0.690    0.059   11.671    0.000\n   .ags9              0.386    0.036   10.769    0.000\n   .ags11             0.831    0.071   11.639    0.000\n   .ags4              0.588    0.045   12.959    0.000\n   .ags8              0.815    0.070   11.602    0.000\n   .ags10             0.362    0.043    8.423    0.000\n    map               0.706    0.083    8.514    0.000\n    mav               0.852    0.128    6.655    0.000\n    pap               1.648    0.158   10.416    0.000\n    pav               0.864    0.094    9.198    0.000\n\nsemPlot::semPaths(h1.fit)\n\n\n\n\nThat’s a lot of outputs. Let’s talk about what’s here.\n\n\n2.2.3 Goodness of Fit Statistics\n\n2.2.3.1 Chi-Squared Statistic\nThe main thing to look at is the chi-squared statistic from the ‘User Model’, IE the model I, the user, have just fit. I like to think of this as a measure of how different the model’s reconstructed correlation matrix looks compared to the actual empirical correlation matrix of the data. So we use this statistic to test the null hypothesis “there is no significant difference between model’s reconstructed correlation matrix and the empirical one”. So, confusingly, we’re actually hoping to accept the null hypothesis here. This model returns a value of 328.312 with a vanishingly small p-value, so we reject the null hypothesis, which is bad: it suggests our model isn’t doing a good job replicating the empirical correlation matrix.\nHere’s a quote from Gorsuch (1983) that explains this stuff from the slightly different angle:\n\n“The test of significance [for a CFA model fit by maximum likelihood] gives a chi-square statistic with the null hypothesis being that all the population covariance has been extracted by the hypothesized number of factors. If the chi-square is significant at the designated probability level, then the residual matrix still has significant covariance in it.”\n\nSo this chi-squared statistic provides a first look at goodness-of-fit, but @Finch2015 say it is actually not very trustworthy in practice because the null hypothesis is sort of crazy: we want a more permissive test than just whether the model is perfectly recreating the empirical correlation matrix.\n\n“this statistic is not particularly useful in practice because it tests the null hypothesis that [the model-reconstructed correlation matrix is equal to the empirical correlation matrix], which is very restrictive. The test will almost certainly be rejected when the sample size is sufficiently large… In addition, the chi-square test relies on the assumption of multivariate normality of the indicators, which may not be tenable in many situations.”\n\nSo we’re gonna wanna look at statistics other than just chi-squared for goodness-of-fit.\n\n\n2.2.3.2 Root Mean Squared Error Approximation (RMSEA)\nAnother one people like to go with is the Root Mean Squared Error Approximation (RMSEA). This statistic takes some math and background to understand, which I’m not going to go over here. I found this document to be the clearest (but also pretty mathy) explanation.\nEssentially RMSEA is a weighted sum of the discrepancies between the model’s reconstructed correlation matrix and the empirical correlation matrix. But it also does a nice thing where it discounts model complexity and sample size to help us not overfit. Here’s the definition:\n\\(\\text{RMSEA} = \\sqrt{\\dfrac{χ^2 - \\text{df}}{\\text{df}(n-1)}}\\)\nSee how it takes the chi-squared statistic and divides it by degrees of freedom (as a proxy for model complexity) and sample size? This makes for a more conservative measure of goodness-of-fit. Apparently the square-root is used “to return the index to the same metric as the original standardized parameters”. I don’t really understand that part.\nAs with the raw chi-squared statistic, we want RMSEA to be small because it is intended as a measure of the distance between the empirical correlation matrix and the model-estimated correlation matrix. According to Finch (2015), people like to say:\n\nRMSEA <= 0.05 is a ‘good fit’;\n0.05 < RMSEA <= 0.08 is an ‘ok fit’\nRMSEA > .08 is a ‘bad fit’.\n\nComparative Fit Index (CFI)"
  },
  {
    "objectID": "cfa.html#example-2",
    "href": "cfa.html#example-2",
    "title": "2  CFA",
    "section": "2.3 Example 2:",
    "text": "2.3 Example 2:\n\ndat_ff <- foreign::read.spss('data/finch-and-french/performance.data.sav')\n\n# Seems like I need to only use the first 12 columns I think?\ndat_ff <- dat_ff %>% \n  \n  as_tibble() %>% \n  \n  select(1:12)\n\nNext we’ll do another example from Finch (2015), from the SEM chapter on page 62. They say it is important to CFA first before testing the relationships between the latent variables a la SEM, because we first want to make sure those latent variables actually seem good. This example uses a different dataset than the previous one.\n\n[W]e must ascertain whether the proposed model structure is supported by our data, which we will do by fitting a CFA to each of the latent variables…\n\nThe authors fit a CFA for each of the latent variables in isolation, namely Mastery, Self-Oriented Perfectionism, and ‘ATTC’, which seems to mean ‘Attention Control’"
  },
  {
    "objectID": "cfa.html#example-3",
    "href": "cfa.html#example-3",
    "title": "2  CFA",
    "section": "2.4 Example 3:",
    "text": "2.4 Example 3:\nNow we’ll look at an example from Kline (2011), chapter 13.\nLoad the data:\n\ndat_kline <- read_csv('data/kline/kabc-amos.csv')\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n\n\nRows: 11 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): rowtype_, varname_\ndbl (8): HM, NR, WO, GC, Tr, SM, MA, PS\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "cfa.html#example-4",
    "href": "cfa.html#example-4",
    "title": "2  CFA",
    "section": "2.5 Example 4:",
    "text": "2.5 Example 4:\nLastly, let’s walk through an example from the lavaan documentation\n\n\n\n\nFinch, French, W. Holmes. 2015. Latent Variable Modeling with r.\n\n\nGorsuch, Richard L. 1983. Factor Analysis, 2nd Edition.\n\n\nKline, Rex B. 2011. Principles and Practice of Structural Equation Modeling."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Finch, French, W. Holmes. 2015. Latent Variable Modeling with\nr.\n\n\nGorsuch, Richard L. 1983. Factor Analysis, 2nd Edition.\n\n\nKline, Rex B. 2011. Principles and Practice of Structural Equation\nModeling."
  }
]