<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.242">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Latent Variable Modelling Workflow Reference - 2&nbsp; CFA</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./sem.html" rel="next">
<link href="./intro.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">CFA</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Latent Variable Modelling Workflow Reference</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cfa.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">CFA</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./sem.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">SEM</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#the-whole-game" id="toc-the-whole-game" class="nav-link active" data-scroll-target="#the-whole-game">The Whole Game</a></li>
  <li><a href="#example-1-toxic-striving-energy" id="toc-example-1-toxic-striving-energy" class="nav-link" data-scroll-target="#example-1-toxic-striving-energy">Example 1: Toxic Striving Energy</a>
  <ul class="collapse">
  <li><a href="#data-exploration" id="toc-data-exploration" class="nav-link" data-scroll-target="#data-exploration">Data Exploration</a></li>
  <li><a href="#model-fitting" id="toc-model-fitting" class="nav-link" data-scroll-target="#model-fitting">Model Fitting</a></li>
  <li><a href="#goodness-of-fit-statistics" id="toc-goodness-of-fit-statistics" class="nav-link" data-scroll-target="#goodness-of-fit-statistics">Goodness of Fit Statistics</a></li>
  <li><a href="#convergent-validty" id="toc-convergent-validty" class="nav-link" data-scroll-target="#convergent-validty">Convergent Validty</a></li>
  <li><a href="#reliability" id="toc-reliability" class="nav-link" data-scroll-target="#reliability">Reliability</a></li>
  <li><a href="#discriminant-validity" id="toc-discriminant-validity" class="nav-link" data-scroll-target="#discriminant-validity">Discriminant Validity</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul></li>
  <li><a href="#example-2-biodiversity" id="toc-example-2-biodiversity" class="nav-link" data-scroll-target="#example-2-biodiversity">Example 2: Biodiversity</a>
  <ul class="collapse">
  <li><a href="#data-exploration-1" id="toc-data-exploration-1" class="nav-link" data-scroll-target="#data-exploration-1">Data Exploration</a></li>
  <li><a href="#model-fitting-1" id="toc-model-fitting-1" class="nav-link" data-scroll-target="#model-fitting-1">Model Fitting</a></li>
  <li><a href="#modification-indexes" id="toc-modification-indexes" class="nav-link" data-scroll-target="#modification-indexes"><span class="toc-section-number">2.0.1</span>  Modification Indexes</a></li>
  <li><a href="#validity" id="toc-validity" class="nav-link" data-scroll-target="#validity">Validity</a></li>
  </ul></li>
  <li><a href="#example-3-happy-and-sad" id="toc-example-3-happy-and-sad" class="nav-link" data-scroll-target="#example-3-happy-and-sad">Example 3: Happy and Sad</a>
  <ul class="collapse">
  <li><a href="#mtmm-and-error-theory" id="toc-mtmm-and-error-theory" class="nav-link" data-scroll-target="#mtmm-and-error-theory">MTMM and ‘Error Theory’</a></li>
  <li><a href="#simulating-data-based-on-a-dag" id="toc-simulating-data-based-on-a-dag" class="nav-link" data-scroll-target="#simulating-data-based-on-a-dag">Simulating Data Based on a DAG</a></li>
  <li><a href="#correlated-uniqueness-model" id="toc-correlated-uniqueness-model" class="nav-link" data-scroll-target="#correlated-uniqueness-model">Correlated Uniqueness Model</a></li>
  </ul></li>
  <li><a href="#example-4-school-grades" id="toc-example-4-school-grades" class="nav-link" data-scroll-target="#example-4-school-grades"><span class="toc-section-number">2.1</span>  Example 4: School Grades</a>
  <ul class="collapse">
  <li><a href="#measurement-invariance" id="toc-measurement-invariance" class="nav-link" data-scroll-target="#measurement-invariance"><span class="toc-section-number">2.1.1</span>  Measurement Invariance</a></li>
  <li><a href="#multigroup-cfa" id="toc-multigroup-cfa" class="nav-link" data-scroll-target="#multigroup-cfa">Multigroup CFA</a></li>
  </ul></li>
  <li><a href="#example-5-longitudinal-measurement-invariance" id="toc-example-5-longitudinal-measurement-invariance" class="nav-link" data-scroll-target="#example-5-longitudinal-measurement-invariance"><span class="toc-section-number">2.2</span>  Example 5: Longitudinal Measurement Invariance</a></li>
  <li><a href="#session-info" id="toc-session-info" class="nav-link" data-scroll-target="#session-info"><span class="toc-section-number">2.3</span>  Session Info</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">CFA</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lavaan)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggdag)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="the-whole-game" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="the-whole-game">The Whole Game</h2>
<p>I think it is safe to say that The Whole Game of Confirmatory Factor Analysis (CFA) is that I’m trying to convince my colleagues that my observed variables are confounded by some unmeasured variables. Usually I’m trying to show that the variables are confounded in a very particular way, where a few small groups of variables are confounded only by one unmeasured variable per group.</p>
<p>So here’s the architypal DAG of a CFA, where the Xs are observed variables, and F1 is an unmeasured variable I am imagining to exist.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set DAG coordinates</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>dag_coords <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> <span class="fu">c</span>(</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">F1 =</span> <span class="dv">1</span>, </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">X1 =</span> <span class="dv">2</span>,</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">X2 =</span> <span class="dv">2</span>,</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">X3 =</span> <span class="dv">2</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> <span class="fu">c</span>(</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">F1 =</span> <span class="fl">1.5</span>,</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">X1 =</span> <span class="fl">1.8</span>,</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">X2 =</span> <span class="fl">1.5</span>,</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">X3 =</span> <span class="fl">1.2</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Set DAG relationships and aesthetics</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>measurement_confounding_dag <span class="ot">&lt;-</span> ggdag<span class="sc">::</span><span class="fu">dagify</span>(</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>  X1 <span class="sc">~</span> F1,</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>  X2 <span class="sc">~</span> F1,</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>  X3 <span class="sc">~</span> F1,</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>  <span class="at">coords =</span> dag_coords</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> </span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy_dagitty</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    <span class="st">`</span><span class="at"> </span><span class="st">`</span> <span class="ot">=</span> <span class="fu">case_when</span>(</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>      <span class="fu">grepl</span>(<span class="st">"^F"</span>, name) <span class="sc">~</span> <span class="st">"latent"</span>,</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>      <span class="fu">grepl</span>(<span class="st">"^X"</span>, name) <span class="sc">~</span> <span class="st">"observed"</span></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>    ))</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the DAG</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>measurement_confounding_dag <span class="sc">%&gt;%</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y, <span class="at">xend =</span> xend, <span class="at">yend =</span> yend)) <span class="sc">+</span></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_dag_point</span>(<span class="fu">aes</span>(<span class="at">colour =</span> <span class="st">`</span><span class="at"> </span><span class="st">`</span>)) <span class="sc">+</span></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_colour_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"dark blue"</span>, <span class="st">"#edbc64"</span>)) <span class="sc">+</span> </span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_dag_edges</span>() <span class="sc">+</span></span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_dag_text</span>() <span class="sc">+</span></span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.title =</span> <span class="fu">element_blank</span>()) <span class="sc">+</span></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_void</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="cfa_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The Whole Game of CFA is to convince your reader that the patterns of variance and covariance in your data are consistent with the above DAG (or some other version of it).</p>
<p>The classic way of testing whether your data are consistent with a DAG is to condition on some of the variables, perhaps by including it as a predictor in a linear regression model, and see whether the patterns of correlation change in the ways the DAG expects based on the rules of d-separation. For the above DAG, this would mean controlling for F1 and seeing whether the correlations between X1, X2, and X3 decrease as a result.</p>
<p>But in CFA we always assume the confounder is unmeasured, so we can’t directly control for it. Instead, we can only try to argue for our DAG in a more hand-wavy sort of way: we expect confounded variables to be correlated with each other, and uncounfounded variables to <em>not</em> be correlated with each other. This is why we focus on the empirical correlation matrix as the basis for our model: if a few of my variables are very correlated with each other then that is <em>consistent</em> with them being confounded by the same unobserved variable. But it is not proof! You can never prove a DAG, after all.</p>
<p>So interpreting a CFA model is all about checking to see whether the correlations between the variables are consistent with what we would expect to see under the DAG where each group of variables is confounded by a single unmeasured variable.</p>
<p>Let’s look at some examples of how people have liked to make the case for their missing-confounder DAG.</p>
</section>
<section id="example-1-toxic-striving-energy" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="example-1-toxic-striving-energy">Example 1: Toxic Striving Energy</h2>
<p>The first example we’ll look at is from <span class="citation" data-cites="Finch2015">Finch (<a href="#ref-Finch2015" role="doc-biblioref">2015</a>)</span>, chapter 3. The practice dataset is introduced on page 10. It is from a study about human motivation. The dataset is a weird questionnaire called the ‘Achievement Goal Scale’ (AGS), which asks people 12 questions about how much toxic striving energy they have. The dataset provided seems to have lots of mysterious columns in it, but we’re probably good to just keep the columns with responses to the AGS questionnaire:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="do">### Load the data</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>dat_raw <span class="ot">&lt;-</span> foreign<span class="sc">::</span><span class="fu">read.spss</span>(<span class="st">'data/finch-and-french/edps744.sav'</span>) </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="do">### Clean the data</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>dat_ags <span class="ot">&lt;-</span> dat_raw <span class="sc">%&gt;%</span> </span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Convert to a data frame for ease of use</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.data.frame</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Keep only columns that start with the prefix 'ags' followed by a question number</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="fu">matches</span>(<span class="st">"ags</span><span class="sc">\\</span><span class="st">d"</span>)) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="data-exploration" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="data-exploration">Data Exploration</h3>
<p>We don’t want to do too much exploration before fitting our factor models, because the whole game of CFA is to commit to our hypotheses before checking what the data looks like, so we don’t mislead ourselves with <a href="http://www.stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf">forking paths</a>. But just for fun, we can explore the distributions of the answers to each of the 12 questions:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>dat_ags <span class="sc">%&gt;%</span> </span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Pivot to prepare the data for visualization</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">cols      =</span> <span class="fu">everything</span>(),</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">names_to  =</span> <span class="st">"question"</span>,</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">values_to =</span> <span class="st">"response"</span>,</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">names_transform =</span> <span class="fu">list</span>(<span class="at">question =</span> fct_inorder)  </span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Plot</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">x =</span> response)) <span class="sc">+</span> </span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span> </span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>question)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="cfa_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Seems like some questions have different means and variances from each other. For example, the answers to <code>ags11</code> and <code>ags12</code> are relatively flat, while the answers to <code>ags4</code> and <code>ags5</code> are more bunched up around the highest values. The responses clearly skew towards higher values in aggregate.</p>
<p>We can also do some healthy exploration of missingness in the dataset. For starters: what proportion of values are missing in each row?</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>dat_ags <span class="sc">%&gt;%</span> </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Calculate the proportion of missing values </span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise_all</span>(<span class="sc">~</span> <span class="fu">sum</span>(<span class="fu">is.na</span>(.)) <span class="sc">/</span> (<span class="fu">sum</span>(<span class="fu">is.na</span>(.) <span class="sc">+</span> <span class="fu">sum</span>(<span class="sc">!</span><span class="fu">is.na</span>(.))))) <span class="sc">%&gt;%</span> </span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Rounding to make the results more presentable</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="fu">everything</span>(), round, <span class="dv">6</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Create the table</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="at">title =</span> <span class="st">"Proportion of Missing Responses in Each Column"</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="table table-sm table-striped">
<colgroup>
<col style="width: 8%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: right;">ags1</th>
<th style="text-align: right;">ags2</th>
<th style="text-align: right;">ags3</th>
<th style="text-align: right;">ags4</th>
<th style="text-align: right;">ags5</th>
<th style="text-align: right;">ags6</th>
<th style="text-align: right;">ags7</th>
<th style="text-align: right;">ags8</th>
<th style="text-align: right;">ags9</th>
<th style="text-align: right;">ags10</th>
<th style="text-align: right;">ags11</th>
<th style="text-align: right;">ags12</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1.1e-05</td>
<td style="text-align: right;">5e-06</td>
<td style="text-align: right;">5e-06</td>
<td style="text-align: right;">1.6e-05</td>
<td style="text-align: right;">1.6e-05</td>
<td style="text-align: right;">1.1e-05</td>
<td style="text-align: right;">1.6e-05</td>
<td style="text-align: right;">1.6e-05</td>
<td style="text-align: right;">1.1e-05</td>
<td style="text-align: right;">2.2e-05</td>
<td style="text-align: right;">1.1e-05</td>
<td style="text-align: right;">1.6e-05</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>That’s very little missingness. Probably no need to do multiple imputation here.</p>
<p>The authors also do a preliminary test of whether the responses are normally distributed, since this is one of the fundamental assumptions of maximum likelihood estimation. Kristoffer Magnusson has created <a href="https://rpsychologist.com/likelihood/">a cool interactive teaching tool that nicely illustrates this point</a>. It is worth remembering that we <em>do not</em> make this type of assumption for linear regression in general – only for maximum likelihood estimates. All we need assume for linear regression is that the <em>residuals</em> are normally distributed, as opposed to the data themselves. This common misunderstanding can lead researchers to commit what Richard McElreath has called <a href="https://stats.stackexchange.com/questions/515444/histomancy-what-does-mcelreath-propose-we-do-instead">‘histomancy’</a>.</p>
<p>To evaluate the assumption of normalness underlying maximum likelihood estimation, the authors do what seems to be a multivariate version of a classic ‘normal probability plot’. These are explained nicely in <a href="https://stats.stackexchange.com/questions/218638/understanding-normal-probability-plots">this stack exchange thread.</a> They also produce some of the classic tests of skew and kurtosis, which I don’t want to get into here. <a href="https://www.youtube.com/watch?v=TM033GCU-SY&amp;t=26s">This youtuber</a> has nice introductory videos about these topics.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the Mardia tests for normalness</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>mardia.object <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">mardia</span>(dat_ags)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="cfa_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the multivariate version of the normal probability plot</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mardia.object)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Present the outputs we're interested in</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Skew"</span> <span class="ot">=</span> mardia.object<span class="sc">$</span>skew,</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Skew p-value"</span> <span class="ot">=</span> mardia.object<span class="sc">$</span>p.skew,</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Kurtosis"</span> <span class="ot">=</span> mardia.object<span class="sc">$</span>kurtosis,</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Kurtosis p-value"</span> <span class="ot">=</span> mardia.object<span class="sc">$</span>p.kurt</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> </span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th style="text-align: right;">Skew</th>
<th style="text-align: right;">Skew p-value</th>
<th style="text-align: right;">Kurtosis</th>
<th style="text-align: right;">Kurtosis p-value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">2359.475</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">40.52999</td>
<td style="text-align: right;">0</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>The plotted points don’t seem to fit the straight line super well, which suggests that the normalness assumption may not hold here. Also, the hypothesis tests for skew and kurtosis return some mighty low p-values, suggesting that we’ve got lots of each of them. So maybe maximum likelihood estimation isn’t such a good idea here?</p>
<p>The authors proceed with it anyway for pedogogical reasons, because they want to illustrate how the maximum likelihood estimates differ from estimates arrived at using other methods.</p>
<blockquote class="blockquote">
<p>“In actual practice, given the lack of multivariate normality that seems apparent in the previous results, we would likely not use ML and instead rely on the alternative estimation approach.”</p>
</blockquote>
</section>
<section id="model-fitting" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="model-fitting">Model Fitting</h3>
<p>The researchers who collected the data do what good factor analysts do: they look to the literature to set up some clear and specific candidate hypotheses, and see the degree to which this new data is compatible with each of them.</p>
<p>One of the candidate hypotheses is that a person’s toxic striving energy (‘achievement goal orientedness’?) is secretly driven by four platonic unobservable things, namely:</p>
<ol type="1">
<li><p>Mastery Approach ‘MAP’ (eg. <em>“I want to learn as much as possible”)</em>;</p></li>
<li><p>Mastery Avoidant ‘MAV’ (eg. <em>“I want to avoid learning less than I possibly could”</em>);</p></li>
<li><p>Performance Approach ‘PAP’ (eg. <em>“I want to do well compared to other students”);</em></p></li>
<li><p>Performance Avoidant ‘PAV’ (eg. <em>“It is important for me to avoid doing poorly compared to other students”</em>)</p></li>
</ol>
<p>We’ll call the above hypothesis <strong>H1.</strong> But there’s another hypothesis that says actually the ‘Mastery’ variables are just one monolithic thing, so really there are only 3 factors, namely ‘Mastery’, ‘PAP’, and ‘PAV’. We’ll call this one <strong>H2.</strong> These will be the two candidate hypotheses we’re gonna test via factor analysis.</p>
<p>The way <strong>lavaan</strong> works is that you need to separately define the model syntax as a string, and then feed that string to one of the model-fitting functions like <code>cfa()</code> . Then we can call the <code>summary()</code> function to get a big table of outputs.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the relationships from my hypothesis</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>h1.definition <span class="ot">&lt;-</span> </span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="st">'map=~ags1+ags5+ags7</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="st">mav=~ags2+ags6+ags12</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="st">pap=~ags3+ags9+ags11</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="st">pav=~ags4+ags8+ags10'</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>h1.fit <span class="ot">&lt;-</span> <span class="fu">cfa</span>(</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">data  =</span> dat_ags,</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">model =</span> h1.definition</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Look at the results</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>h1.summary <span class="ot">&lt;-</span> <span class="fu">summary</span>(h1.fit, <span class="at">fit.measures =</span> <span class="cn">TRUE</span>, <span class="at">standardized =</span> <span class="cn">TRUE</span>)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>h1.summary</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6-12 ended normally after 48 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                        30

                                                  Used       Total
  Number of observations                           419         432

Model Test User Model:
                                                      
  Test statistic                               328.312
  Degrees of freedom                                48
  P-value (Chi-square)                           0.000

Model Test Baseline Model:

  Test statistic                              3382.805
  Degrees of freedom                                66
  P-value                                        0.000

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    0.915
  Tucker-Lewis Index (TLI)                       0.884

Loglikelihood and Information Criteria:

  Loglikelihood user model (H0)              -7014.070
  Loglikelihood unrestricted model (H1)      -6849.914
                                                      
  Akaike (AIC)                               14088.141
  Bayesian (BIC)                             14209.277
  Sample-size adjusted Bayesian (BIC)        14114.078

Root Mean Square Error of Approximation:

  RMSEA                                          0.118
  90 Percent confidence interval - lower         0.106
  90 Percent confidence interval - upper         0.130
  P-value RMSEA &lt;= 0.05                          0.000

Standardized Root Mean Square Residual:

  SRMR                                           0.055

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  map =~                                                                
    ags1              1.000                               0.840    0.746
    ags5              0.774    0.057   13.564    0.000    0.650    0.682
    ags7              1.100    0.064   17.263    0.000    0.924    0.895
  mav =~                                                                
    ags2              1.000                               0.923    0.627
    ags6              0.974    0.078   12.523    0.000    0.899    0.796
    ags12             1.039    0.096   10.805    0.000    0.959    0.644
  pap =~                                                                
    ags3              1.000                               1.284    0.840
    ags9              0.853    0.038   22.349    0.000    1.095    0.870
    ags11             1.103    0.052   21.178    0.000    1.416    0.841
  pav =~                                                                
    ags4              1.000                               0.929    0.771
    ags8              1.599    0.084   19.091    0.000    1.486    0.855
    ags10             1.525    0.073   20.861    0.000    1.418    0.921

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  map ~~                                                                
    mav               0.709    0.079    9.000    0.000    0.914    0.914
    pap               0.066    0.060    1.093    0.274    0.061    0.061
    pav               0.056    0.043    1.289    0.197    0.072    0.072
  mav ~~                                                                
    pap               0.163    0.072    2.265    0.023    0.138    0.138
    pav               0.178    0.053    3.355    0.001    0.207    0.207
  pap ~~                                                                
    pav               1.143    0.102   11.236    0.000    0.958    0.958

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .ags1              0.562    0.047   11.951    0.000    0.562    0.443
   .ags5              0.486    0.038   12.780    0.000    0.486    0.535
   .ags7              0.211    0.032    6.602    0.000    0.211    0.198
   .ags2              1.312    0.102   12.825    0.000    1.312    0.606
   .ags6              0.469    0.049    9.537    0.000    0.469    0.367
   .ags12             1.300    0.103   12.669    0.000    1.300    0.586
   .ags3              0.690    0.059   11.671    0.000    0.690    0.295
   .ags9              0.386    0.036   10.769    0.000    0.386    0.244
   .ags11             0.831    0.071   11.639    0.000    0.831    0.293
   .ags4              0.588    0.045   12.959    0.000    0.588    0.405
   .ags8              0.815    0.070   11.602    0.000    0.815    0.269
   .ags10             0.362    0.043    8.423    0.000    0.362    0.153
    map               0.706    0.083    8.514    0.000    1.000    1.000
    mav               0.852    0.128    6.655    0.000    1.000    1.000
    pap               1.648    0.158   10.416    0.000    1.000    1.000
    pav               0.864    0.094    9.198    0.000    1.000    1.000</code></pre>
</div>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>semPlot<span class="sc">::</span><span class="fu">semPaths</span>(h1.fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="cfa_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>That’s a lot of outputs. Let’s break down the output into smaller bite-sized chunks.</p>
</section>
<section id="goodness-of-fit-statistics" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="goodness-of-fit-statistics">Goodness of Fit Statistics</h3>
<section id="chi-squared-statistic" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="chi-squared-statistic">Chi-Squared Statistic</h4>
<p>The first thing to look at is the chi-squared statistic from the ‘User Model’, IE the model I, the user, have just fit. I like to think of this as a measure of how different the model’s reconstructed correlation matrix looks compared to the actual empirical correlation matrix of the data. So we use this statistic to test the null hypothesis “there is no significant difference between model’s reconstructed correlation matrix and the empirical one”. So, confusingly, we’re actually hoping to <em>accept</em> the null hypothesis here. This model returns a value of 328.312 with a vanishingly small p-value, so we reject the null hypothesis, which is bad: it suggests our model isn’t doing a good job replicating the empirical correlation matrix.</p>
<p>Here’s a quote from <span class="citation" data-cites="gorsuch1983">Gorsuch (<a href="#ref-gorsuch1983" role="doc-biblioref">1983</a>)</span> that explains this stuff from the slightly different angle:</p>
<blockquote class="blockquote">
<p>“The test of significance [for a CFA model fit by maximum likelihood] gives a chi-square statistic with the null hypothesis being that all the population covariance has been extracted by the hypothesized number of factors. If the chi-square is significant at the designated probability level, then the residual matrix still has significant covariance in it.”</p>
</blockquote>
<p>So this chi-squared statistic provides a first look at goodness-of-fit, but <span class="citation" data-cites="Finch2015">Finch (<a href="#ref-Finch2015" role="doc-biblioref">2015</a>)</span> say it is actually not very trustworthy in practice because the null hypothesis is sort of crazy: we want a more permissive test than just whether the model is <em>perfectly</em> recreating the empirical correlation matrix.</p>
<blockquote class="blockquote">
<p>“this statistic is not particularly useful in practice because it tests the null hypothesis that [the model-reconstructed correlation matrix is equal to the empirical correlation matrix], which is very restrictive. The test will almost certainly be rejected when the sample size is sufficiently large… In addition, the chi-square test relies on the assumption of multivariate normality of the indicators, which may not be tenable in many situations.”</p>
</blockquote>
<p>So we’re gonna wanna look at statistics other than just chi-squared for goodness-of-fit, but it seems like a fine place to start. Let’s look at the chi-squared statistic of our model:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="do">### Create a nice summary table</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">Test             =</span> <span class="st">"standard chi-squared"</span>,</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">DF</span><span class="st">`</span>             <span class="ot">=</span> h1.summary<span class="sc">$</span>test<span class="sc">$</span>standard<span class="sc">$</span>df,</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">Test Statistic</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">round</span>(h1.summary<span class="sc">$</span>test<span class="sc">$</span>standard<span class="sc">$</span>stat, <span class="dv">2</span>),</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">p-value</span><span class="st">`</span>        <span class="ot">=</span> h1.summary<span class="sc">$</span>test<span class="sc">$</span>standard<span class="sc">$</span>pvalue</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> </span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="fu">everything</span>(), as.character)) <span class="sc">%&gt;%</span> </span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="fu">everything</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th style="text-align: left;">name</th>
<th style="text-align: left;">value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Test</td>
<td style="text-align: left;">standard chi-squared</td>
</tr>
<tr class="even">
<td style="text-align: left;">DF</td>
<td style="text-align: left;">48</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Test Statistic</td>
<td style="text-align: left;">328.31</td>
</tr>
<tr class="even">
<td style="text-align: left;">p-value</td>
<td style="text-align: left;">0</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>It takes lots of skill and experience to have a sense of whether a test statistic is big or small given the degrees of freedom at play, but we can see from the p-value that we reject the null hypothesis in a big way. This is bad – it suggests that, given our assumptions, there’s a big difference between our model and the data.</p>
</section>
<section id="root-mean-squared-error-approximation-rmsea" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="root-mean-squared-error-approximation-rmsea">Root Mean Squared Error Approximation (RMSEA)</h4>
<p>Another one people like to go with is the Root Mean Squared Error Approximation (RMSEA). This statistic takes some math and background to understand, which I’m not going to go over here. I found <a href="http://www.statpower.net/Content/312/Handout/Measures%20of%20Fit%20in%20Structural%20Equation%20Modeling.pdf">this document</a> to be the clearest (but also pretty mathy) explanation.</p>
<p>Essentially, RMSEA is a weighted sum of the discrepancies between the model’s reconstructed correlation matrix and the empirical correlation matrix. But it also does a nice thing where it discounts model complexity and sample size to help us not overfit. Here’s the definition:</p>
<p><span class="math inline">\(\text{RMSEA} = \sqrt{\dfrac{χ^2 - \text{df}}{\text{df}(n-1)}}\)</span></p>
<p>See how it takes the chi-squared statistic and divides it by degrees of freedom (as a proxy for model complexity) and sample size? This makes for a more conservative measure of goodness-of-fit. Apparently the square-root is used <em>“to return the index to the same metric as the original standardized parameters”</em>. I don’t really understand that part… is it because a Chi-squared random variable is the squared version of a normal standard variable?</p>
<p>As with the raw chi-squared statistic, we want RMSEA to be small because it is intended as a measure of the distance between the empirical correlation matrix and the model-estimated correlation matrix. According to <span class="citation" data-cites="Finch2015">Finch (<a href="#ref-Finch2015" role="doc-biblioref">2015</a>)</span>, people like to say:</p>
<ul>
<li><p>RMSEA &lt;= 0.05 is a ‘good fit’;</p></li>
<li><p>0.05 &lt; RMSEA &lt;= 0.08 is an ‘ok fit’</p></li>
<li><p>RMSEA &gt; .08 is a ‘bad fit’.</p></li>
</ul>
<p>Let’s check the RMSEA of our model:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make a nice summary table</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>h1.summary<span class="sc">$</span>fit <span class="sc">%&gt;%</span> </span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tibble</span>(<span class="at">rownames =</span> <span class="st">"stat"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">str_detect</span>(stat, <span class="st">"rmsea"</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th style="text-align: left;">stat</th>
<th style="text-align: right;">value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">rmsea</td>
<td style="text-align: right;">0.1180574</td>
</tr>
<tr class="even">
<td style="text-align: left;">rmsea.ci.lower</td>
<td style="text-align: right;">0.1061525</td>
</tr>
<tr class="odd">
<td style="text-align: left;">rmsea.ci.upper</td>
<td style="text-align: right;">0.1303058</td>
</tr>
<tr class="even">
<td style="text-align: left;">rmsea.pvalue</td>
<td style="text-align: right;">0.0000000</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Yikes – looks like our whole RMSEA, as well as its confidence interval, are above the ‘bad fit’ conventional threshold of .08. This corroborates what we saw with the chi-squared statistic above.</p>
</section>
<section id="comparative-fit-index-cfi-and-tucker-lewis-index-tli" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="comparative-fit-index-cfi-and-tucker-lewis-index-tli">Comparative Fit Index (CFI) and Tucker-Lewis Index (TLI)</h4>
<p>CFI seems to be the most trusted and widely-used tool for assessing goodness of fit in a CFA. Basically the idea is that we ask: “how much does the chi-squared statistic of my model differ from the chi-squared statistic of the worst model I can think of?”, where the conventional “worst model I can think of” is the model where I assume all of my observed variables are totally uncorrelated. This sort of has the opposite flavour of the deviance statistic I’m already familiar with, which compares the current model with “the best model I can think of.”</p>
<p><span class="math inline">\(\text{CFI} = 1 - \dfrac{\text{max}(χ^2_T - \text{df}_T, 0)}{\text{max}(χ^2_0 - \text{df}_0, 0)}\)</span></p>
<p>Actually, the numerator and denominator are both equal to the ‘non-centrality parameter’ of their respective candidate distributions. I’m not gonna get into this, but this is an idea that also shows up in power analysis as a way of comparing the null and candidate hypotheses.</p>
<p>We want to end up with a CFI as close to 1 as possible, because that suggests a big difference between my model and the worst possible model. So people say we can sort of think of this as analogous to <span class="math inline">\(R^2\)</span> from linear regression. People seem to have adopted 0.95 as am arbitrary cutoff for ‘good fit’ for the CFI.</p>
<p>If you want to learn more about the CFI, I found <a href="https://scholarworks.umass.edu/cgi/viewcontent.cgi?article=1561&amp;context=pare">this article</a> a well-written resource.</p>
<p>Tucker-Lewis Index seems to be pretty similar to CFI, and we interpret it in the same way. Let’s look at both of them:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a nice summary table</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>h1.summary<span class="sc">$</span>fit <span class="sc">%&gt;%</span> </span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tibble</span>(<span class="at">rownames =</span> <span class="st">"stat"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">str_detect</span>(stat, <span class="st">"cfi|tli"</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th style="text-align: left;">stat</th>
<th style="text-align: right;">value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">cfi</td>
<td style="text-align: right;">0.9154874</td>
</tr>
<tr class="even">
<td style="text-align: left;">tli</td>
<td style="text-align: right;">0.8837951</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Looks like the CFI and TLI look ok, but don’t meet the conventional .95 cutoff. So they are in line with the chi-squared and RMSEA in suggesting that our goodness-of-fit isn’t so good.</p>
</section>
</section>
<section id="convergent-validty" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="convergent-validty">Convergent Validty</h3>
<p>Like I said before: when I’m doing factor analysis, my goal is to convince my research peers that my observed variables are confounded by an unobserved variable, and that therefore they provide a way of ‘measuring’ that unobserved variable. This seems like an ontologically dubious framing, and it also seems impossible to prove. But people who do research have settled on a few ways of trying to make this case.</p>
<p>One such way is to take all of the measured variables I’m imagining to be caused by the same unmeasured factor and show that they are indeed correlated with each other, because this is what we would expect under the simple DAG where they are all confounded by the same latent variable. When this happens, I can say that my factor has <strong>Convergent Validity.</strong> In the words of <span class="citation" data-cites="gorsuch1983">Gorsuch (<a href="#ref-gorsuch1983" role="doc-biblioref">1983</a>)</span>:</p>
<blockquote class="blockquote">
<p><em>“Convergent validity occurs when several variables deemed to measure the same construct correlate with each other.”</em></p>
</blockquote>
<p>Or, as <span class="citation" data-cites="Kline2011">Kline (<a href="#ref-Kline2011" role="doc-biblioref">2011</a>)</span> puts it:</p>
<blockquote class="blockquote">
<p><em>“Variables presumed to measure the same construct show convergent validity if their intercorrelations are appreciable in magnitude.”</em></p>
</blockquote>
<p>It seems like to make the jump from ‘these measured variables are correlated’ to ‘these measured variables are <em>caused</em> by a single shared latent factor’ I would need to be also making the further assumption that there aren’t <em>other</em> unmeasured confounders muddying up the observed covariances. It’s DAGs all the way down…</p>
<p>Based on the textbooks I’m working from, here are a few questions I can answer if I want to make the case for Convergent Validity:</p>
<ol type="1">
<li>Are the factor loadings statistically significant?</li>
<li>Are the standardized factor loadings pretty big (IE pretty close to 1)?</li>
<li>Are the standardized within-factor loadings pretty similar to each other?</li>
<li>Do the measurements seem to have good ‘reliability’ as measured by something like Chronbach’s Alpha, Average Variance Extracted, or Composite Reliability?</li>
<li>Are all of the residual variances less than .50, IE is the model explaining at least half the variance of each model?</li>
</ol>
<p>First we can look at the factor loadings. These are essentially just the regression coefficients of each factor on each of the outcome variables for which it was allowed to be a covariate. So we want them to be big and significant.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="do">### Make a nice summary table of the factor loadings</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>h1.summary<span class="sc">$</span>pe <span class="sc">%&gt;%</span> </span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tibble</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Keep only the rows with info on factor loadings</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Clean up the important values, then combine them into a single column</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">std.all =</span> <span class="fu">round</span>(std.all, <span class="dv">2</span>),</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">std.all =</span> <span class="fu">paste0</span>(std.all, <span class="st">", pvalue = "</span>, pvalue, <span class="st">")"</span>)</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>  <span class="co"># reformat the table</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(lhs, rhs, std.all) <span class="sc">%&gt;%</span> </span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_wider</span>(</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">names_from =</span> <span class="st">"lhs"</span>, </span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">values_from =</span> <span class="st">"std.all"</span>,</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">values_fill =</span> <span class="st">"0"</span></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">column_to_rownames</span>(<span class="st">"rhs"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="at">caption =</span> <span class="st">"Standardized factor loadings and p-values"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="table table-sm table-striped">
<caption>Standardized factor loadings and p-values</caption>
<colgroup>
<col style="width: 7%">
<col style="width: 23%">
<col style="width: 23%">
<col style="width: 23%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">map</th>
<th style="text-align: left;">mav</th>
<th style="text-align: left;">pap</th>
<th style="text-align: left;">pav</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">ags1</td>
<td style="text-align: left;">0.75, pvalue = NA)</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">ags5</td>
<td style="text-align: left;">0.68, pvalue = 0)</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">ags7</td>
<td style="text-align: left;">0.9, pvalue = 0)</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">ags2</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0.63, pvalue = NA)</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">ags6</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0.8, pvalue = 0)</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">ags12</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0.64, pvalue = 0)</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">ags3</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0.84, pvalue = NA)</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">ags9</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0.87, pvalue = 0)</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">ags11</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0.84, pvalue = 0)</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">ags4</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0.77, pvalue = NA)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">ags8</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0.85, pvalue = 0)</td>
</tr>
<tr class="even">
<td style="text-align: left;">ags10</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0.92, pvalue = 0)</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Firstly, notice that all of the non-fixed loadings are highly statistically significant, with all p-values smaller than .01. This is good! Super statistically-significant loadings are a necessary sign that our measured variables are actually good proxies for the imaginary ‘latent’ factor we’re purporting to use them to measure.</p>
<p>Next, <span class="citation" data-cites="Kline2011">Kline (<a href="#ref-Kline2011" role="doc-biblioref">2011</a>)</span> says that we can start assessing convergent validity by just looking at the standardized loadings can in isolation. In his words on page 344:</p>
<blockquote class="blockquote">
<p><em>“[with reference to a CFA model he has fit]: A few other standardized coefficients are rather low, such as .433 for the self-talk indicator of constructive thinking, so evidence for convergent validity is mixed.”</em></p>
</blockquote>
<p>To my eye it looks like some of the standardized loadings on the ‘mav’ factor are pretty low. Also, it seems like only ‘pap’ has really consistent loadings across all of its measured variables: the other three factors all have a bunch of variance between their loadings. So this all seems like a bit of a red flag.</p>
<p><span class="citation" data-cites="Kline2011">Kline (<a href="#ref-Kline2011" role="doc-biblioref">2011</a>)</span>, on page 307, gives yet another way of assessing convergent validity: he fits a CFA, then asks whether “the majority” of the variances of the observed variables have been explained, IE whether the standardized residual variances are &lt;50. I guess the idea is that the amount of variance explained for a variable by a factor depends on how correlated In his words:</p>
<blockquote class="blockquote">
<p>“[in reference to one of his models:] [the] model fails to explain the majority (&gt; .50) of variance for a total of four out of eight indicators, which indicates poor convergent validity.”</p>
</blockquote>
<p>Let’s have a look at the residual variances. These are just the proportion of the empirical variance of each measured variable that is left unexplained by the linear models that make up the factor analysis.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>h1.summary<span class="sc">$</span>pe <span class="sc">%&gt;%</span> </span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.data.frame</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">grepl</span>(<span class="st">"ags</span><span class="sc">\\</span><span class="st">d"</span>, lhs)) <span class="sc">%&gt;%</span> </span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">factor =</span> <span class="fu">case_when</span>(</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    lhs <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"ags1"</span>, <span class="st">"ags5"</span>, <span class="st">"ags7"</span>) <span class="sc">~</span> <span class="st">"map"</span>,</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    lhs <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"ags2"</span>, <span class="st">"ags6"</span>, <span class="st">"ags12"</span>) <span class="sc">~</span> <span class="st">"mav"</span>,</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    lhs <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"ags3"</span>, <span class="st">"ags9"</span>, <span class="st">"ags11"</span>) <span class="sc">~</span> <span class="st">"pap"</span>,</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>    lhs <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"ags4"</span>, <span class="st">"ags8"</span>, <span class="st">"ags10"</span>) <span class="sc">~</span> <span class="st">"pav"</span>,</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>  )) <span class="sc">%&gt;%</span> </span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(factor, <span class="st">"var"</span> <span class="ot">=</span> lhs, std.all) <span class="sc">%&gt;%</span> </span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th style="text-align: left;">factor</th>
<th style="text-align: left;">var</th>
<th style="text-align: right;">std.all</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">map</td>
<td style="text-align: left;">ags1</td>
<td style="text-align: right;">0.4434896</td>
</tr>
<tr class="even">
<td style="text-align: left;">map</td>
<td style="text-align: left;">ags5</td>
<td style="text-align: right;">0.5345470</td>
</tr>
<tr class="odd">
<td style="text-align: left;">map</td>
<td style="text-align: left;">ags7</td>
<td style="text-align: right;">0.1980907</td>
</tr>
<tr class="even">
<td style="text-align: left;">mav</td>
<td style="text-align: left;">ags2</td>
<td style="text-align: right;">0.6063553</td>
</tr>
<tr class="odd">
<td style="text-align: left;">mav</td>
<td style="text-align: left;">ags6</td>
<td style="text-align: right;">0.3670913</td>
</tr>
<tr class="even">
<td style="text-align: left;">mav</td>
<td style="text-align: left;">ags12</td>
<td style="text-align: right;">0.5858185</td>
</tr>
<tr class="odd">
<td style="text-align: left;">pap</td>
<td style="text-align: left;">ags3</td>
<td style="text-align: right;">0.2950189</td>
</tr>
<tr class="even">
<td style="text-align: left;">pap</td>
<td style="text-align: left;">ags9</td>
<td style="text-align: right;">0.2436200</td>
</tr>
<tr class="odd">
<td style="text-align: left;">pap</td>
<td style="text-align: left;">ags11</td>
<td style="text-align: right;">0.2927905</td>
</tr>
<tr class="even">
<td style="text-align: left;">pav</td>
<td style="text-align: left;">ags4</td>
<td style="text-align: right;">0.4050030</td>
</tr>
<tr class="odd">
<td style="text-align: left;">pav</td>
<td style="text-align: left;">ags8</td>
<td style="text-align: right;">0.2694999</td>
</tr>
<tr class="even">
<td style="text-align: left;">pav</td>
<td style="text-align: left;">ags10</td>
<td style="text-align: right;">0.1526773</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Looks like the model has mostly done a good job for the ‘Performance’ factors, with all variables having at least ~60% of their variance explained. But the ‘Mastery’ factors are worse, especially ‘mav’, with two of its three variables having only ~40% of their variances explained. This is yet more evidence that the ‘mav’ factor isn’t doing so great a job.</p>
<p>~~Lastly, Gorsuch suggests another way of testing for convergent validity:</p>
<blockquote class="blockquote">
<p><em>factor loadings of several variables hypothesized to relate to the construct can also be tested for significance. They could be specified as equal for the one model and the chi-square for that model subtracted from another hypothesized factor structure where they are allowed to vary. If the two differ significantly from each other, then one or more of the variables is more related to the construct than one or more of the other variables.”</em></p>
</blockquote>
<p>Let’s try this out: we’ll fit another model that assumes all of the within-factor loadings are equal, and see if that results in a statistically significant reduction in goodness-of-fit. If it does, then we lose some evidence of convergent validity.~~</p>
</section>
<section id="reliability" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="reliability">Reliability</h3>
<p>In looking for Convergent Validity we were mostly just comparing the parameter estimates (loadings) and residual variances of individual variables. We were trying to figure out whether these variables belong together. But in addition to tests of validity to decide which columns belong in the scale, people like to test the overall scale itself by invoking the terrible concept named <strong>‘Reliability’</strong>. Reliability purports to be ‘true variance in the underlying construct’ as a proportion of ‘total variance in the scores of a subscale’. This seems to me like an ontologically dubious concept, but it’s what we’re working with.</p>
<p>This all feels pretty similar to Convergent Validity to me. We’re just trying to show that the data are consistent with all of the factor-level columns being confounded by the same variable.</p>
<p>The all-time classic ‘reliability’ measure is called <strong>Cronbach’s Alpha.</strong> Cronbach didn’t actually invent it, so hello <a href="https://en.wikipedia.org/wiki/Stigler%27s_law_of_eponymy">Stigler’s Law</a>. Here’s what it looks like:</p>
<p><span class="math inline">\(\alpha = (\dfrac{k}{1-k}) (1 - \dfrac{\sum\sigma_y^2}{\sigma_T^2})\)</span></p>
<p>The term on the right is doing most of the work: its denominator is the variance of the column that contains the rowwise sums of my dataset. Its numerator is the sum of the variances of each column. So we’re asking: ‘is the variance of the <em>sums</em> larger than the variance of the individual columns?’ This will be true if the columns are generally pretty correlated, because the sums will <em>stack up</em> the raw values, instead of them cancelling each other out. So really we’re just asking: are the columns generally pretty correlated?‘. If my columns are pretty correlated and I make the standard assumption that <em>no other latent factors are influencing my observed values</em> (an insane assumption), then I can feel comfortable saying that Cronbach’s Alpha is useful for figuring out whether my measurements are all loading on the same ’latent’ variable. Since the observed values are gonna be consistent with each other if this is true, people like to say that Cronbach’s Alpha gives a picture of <strong>‘Internal Consistency Reliability’.</strong></p>
<p>Like with Convergent Validity, this is all just another way of asking how correlated my within-factor measured variables are with each other.</p>
<p>Let’s calculate Cronbach’s Alpha for each of the subscales I’ve used to define my supposed factors:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="do">### Split the dataset into the subscales assumed by my factor model</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>subscales <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">map =</span> dat_ags <span class="sc">%&gt;%</span> <span class="fu">select</span>(ags1, ags5, ags7),</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">mav =</span> dat_ags <span class="sc">%&gt;%</span> <span class="fu">select</span>(ags2, ags6, ags12),</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">pap =</span> dat_ags <span class="sc">%&gt;%</span> <span class="fu">select</span>(ags3, ags9, ags11),</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">pav =</span> dat_ags <span class="sc">%&gt;%</span> <span class="fu">select</span>(ags4, ags8, ags10)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="do">### Calculate Chronbach's Alpha for each subscale, then analyze.</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>alphas <span class="ot">&lt;-</span> subscales <span class="sc">%&gt;%</span> </span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">map</span>(psych<span class="sc">::</span>alpha) <span class="sc">%&gt;%</span> </span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">map</span>(summary) <span class="sc">%&gt;%</span> </span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>() </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Reliability analysis   
 raw_alpha std.alpha G6(smc) average_r S/N   ase mean  sd median_r
      0.82      0.82    0.76       0.6 4.6 0.015  5.9 0.9      0.6

Reliability analysis   
 raw_alpha std.alpha G6(smc) average_r S/N   ase mean  sd median_r
      0.77      0.77    0.71      0.52 3.3 0.018  5.3 1.2     0.45

Reliability analysis   
 raw_alpha std.alpha G6(smc) average_r S/N    ase mean  sd median_r
      0.88      0.89    0.84      0.73 7.9 0.0095  5.4 1.3     0.74

Reliability analysis   
 raw_alpha std.alpha G6(smc) average_r S/N  ase mean  sd median_r
      0.87      0.88    0.85       0.7 7.1 0.01  5.6 1.3     0.72</code></pre>
</div>
</div>
<p>According to <span class="citation" data-cites="Kline2011">Kline (<a href="#ref-Kline2011" role="doc-biblioref">2011</a>)</span>, these all look like good results, so they help me feel good about claiming convergent validity:</p>
<blockquote class="blockquote">
<p>“Generally, coefficients around .90 are considered”excellent,” values around .80 as “very good,” and values about .70 as “adequate.””</p>
</blockquote>
<p>Cronbach’s Alpha has some drawbacks as a measure of ‘reliability’, which seem pretty clear to me. For example, as <span class="citation" data-cites="Brown">(<a href="#ref-Brown" role="doc-biblioref"><strong>Brown?</strong></a>)</span> explains:</p>
<ul>
<li><p>What if some of the items in my subscale are confounded by something other than our latent factor? That could make things crazy, IE it could overstate or understate the ‘true’ Cronbach Alpha.</p></li>
<li><p>Even if there’s no other confounding at all, my Cronbach Alpha is going to be understated if my variables are all influenced by the factor to different degrees, IE if the loadings are different, IE if the variables are not ‘Tau-Equivalent’. And this will almost always be the case”</p>
<blockquote class="blockquote">
<p><em>“The condition of tau equivalence is frequently not realized in actual data sets, in part because the units of measurement are often arbitrary.”</em></p>
</blockquote></li>
</ul>
<p>so <span class="citation" data-cites="Kline2011">Kline (<a href="#ref-Kline2011" role="doc-biblioref">2011</a>)</span> says to also calculate the <strong>Average Variance Extracted (AVE)</strong>, which is simply the average of the within-factor squared factor loadings. This is based on the idea that a squared factor loading is the variance explained of the variable by that factor. The convention is that if the AVE &gt; 0.5, then you can feel good about claiming convergent validity. I guess this makes sense – seems like a pretty simple and ad-hoc way of asking whether your loadings are generally on the same page. But obviously if I have lots of observed variables defining the factor then I’m at risk of having a bunch of high loadings and a bunch of low loadings, resulting in a misleadingly moderate average? To me it seems like we might as well just look at the raw loadings themselves – no need to look at an average here.</p>
<p>But just for fun, let’s calculate the AVE. Rather than doing it manually, we can use a ready-made function from the <strong>semTools</strong> package</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>semTools<span class="sc">::</span><span class="fu">AVE</span>(h1.fit) <span class="sc">%&gt;%</span> </span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">map</td>
<td style="text-align: right;">0.6115914</td>
</tr>
<tr class="even">
<td style="text-align: left;">mav</td>
<td style="text-align: right;">0.4556936</td>
</tr>
<tr class="odd">
<td style="text-align: left;">pap</td>
<td style="text-align: right;">0.7179750</td>
</tr>
<tr class="even">
<td style="text-align: left;">pav</td>
<td style="text-align: right;">0.7422385</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Based on the rule-of-thumb that we want the AVE to be at least .50, it seems like the ‘mav’ factor is having some trouble. It also had the lowest Cronbach Alpha. So maybe the observed variables I’m using to measure it aren’t actually doing a great job? This hurts convergent validity for that factor.</p>
<p>Lastly, we can also try to measure this unicorn of ‘reliability’ by just directly asking “what proportion of the total variance is explained by the factor model?”. People like to do this by summing all the factor loadings, squaring that sum, and dividing it by itself plus the sum of the residual variances of the variables (IE dividing it by the total empirical variance of the variable). They call this one the <strong>Composite Reliability (CR).</strong> It is the one that <span class="citation" data-cites="Brown2006">Brown (<a href="#ref-Brown2006" role="doc-biblioref">2006</a>)</span> says to use.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>semTools<span class="sc">::</span><span class="fu">compRelSEM</span>(h1.fit) <span class="sc">%&gt;%</span> </span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">map</td>
<td style="text-align: right;">0.8164263</td>
</tr>
<tr class="even">
<td style="text-align: left;">mav</td>
<td style="text-align: right;">0.6689921</td>
</tr>
<tr class="odd">
<td style="text-align: left;">pap</td>
<td style="text-align: right;">0.8803380</td>
</tr>
<tr class="even">
<td style="text-align: left;">pav</td>
<td style="text-align: right;">0.9016062</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Apparently the rule of thumb for this one is the same as for Cronbach’s Alpha. So we can feel good about all of them except for ‘mav’, which has taken a beating via these 3 checks.</p>
</section>
<section id="discriminant-validity" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="discriminant-validity">Discriminant Validity</h3>
<p>Next let’s look at the estimated correlations between the factors. If my hypothesis H1 is true then we should expect all of the factors to be pretty uncorrelated from each other, but if H2 is true then we should expect MAP and MAV to be super correlated with each other, because H2 thinks there’s no such thing as MAP and MAV – there’s just one big ‘Mastery’ factor:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="do">### Make a nicer version of the correlation matrix of the factors</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>h1.summary<span class="sc">$</span>pe <span class="sc">%&gt;%</span> </span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tibble</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Keep only the rows with info on factor loadings</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice</span>(<span class="dv">25</span><span class="sc">:</span><span class="dv">34</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(lhs, rhs, std.lv) <span class="sc">%&gt;%</span> </span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">std.lv =</span> <span class="fu">round</span>(std.lv, <span class="dv">2</span>),</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">across</span>(<span class="fu">everything</span>(), as.character)</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_wider</span>(</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">names_from =</span> <span class="st">"lhs"</span>, </span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">values_from =</span> <span class="st">"std.lv"</span>,</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">values_fill =</span> <span class="st">" "</span> </span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">column_to_rownames</span>(<span class="st">"rhs"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="at">caption =</span> <span class="st">"Correlation matrix of the factors"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="table table-sm table-striped">
<caption>Correlation matrix of the factors</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">map</th>
<th style="text-align: left;">mav</th>
<th style="text-align: left;">pap</th>
<th style="text-align: left;">pav</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">map</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">mav</td>
<td style="text-align: left;">0.91</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">pap</td>
<td style="text-align: left;">0.06</td>
<td style="text-align: left;">0.14</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">pav</td>
<td style="text-align: left;">0.07</td>
<td style="text-align: left;">0.21</td>
<td style="text-align: left;">0.96</td>
<td style="text-align: left;">1</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Interesting – the ‘Mastery’ factors and the ‘Performance’ factors each seem to be very correlated with each other, while being nice and uncorrelated with the two factors that make up the other. This suggests that we have bad <strong>discriminant validity</strong> between the imagined two types of ‘Mastery’ and two types of ‘Performance’ – the model can’t really tell them apart as separate things. This makes it harder for me to argue that they <em>are</em> in fact separate things. But then again, maybe my hypothesis is that the within-skill factors <em>should</em> be highly correlated. Anyhow, the fact that the ‘Mastery’ and ‘Performance’ factors are all pretty uncorrelated with each other is a good thing for both hypotheses.</p>
<p><span class="citation" data-cites="Brown2006">Brown (<a href="#ref-Brown2006" role="doc-biblioref">2006</a>)</span> gives some nice advice about how to assess discriminant validty, and how to deal with it if you have it:</p>
<blockquote class="blockquote">
<p>“In applied research, a factor correlation that exceeds .80 or .85 is often used as the criterion to define poor discriminant validity. When two factors are highly overlapping, a common research strategy is to respecify the model by collapsing the dimensions into a single factor and determine whether this modification results in a significant degradation in model fit. If the respecified model provides an acceptable fit to the data, it is usually favored because of its superior parsimony.”</p>
<p><span class="citation" data-cites="gorsuch1983">Gorsuch (<a href="#ref-gorsuch1983" role="doc-biblioref">1983</a>)</span> suggests doing something similar:</p>
</blockquote>
<blockquote class="blockquote">
<p><em>“[fit the model] with the qualification that the correlations between one or more of the constructs being tested for discriminant validity is one. The difference between chi-squares from [this model vs the model where the correlations are allowed to freely vary] tests whether the constructs have a correlation significantly less than 1.0. If the correlation between the factors for the two constructs is not significantly different from 1.0, the difference chi-square will be insignificant. This means the null hypothesis of no discriminatory validity would be accepted. If the difference chi-square is significant, then the null hypothesis is rejected and the model that assumes discriminatory validity by allowing the correlation to be less than one is the more appropriate one.”</em></p>
</blockquote>
<p>This has the flavour of a likelihood-ratio test. Let’s do it. First we need to fit the model where the correlation between the Mastery factors and the correlation between the ‘Performance’ factors are both constrained to be 1:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the relationships from my hypothesis</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>h1_orthogonal.definition <span class="ot">&lt;-</span> </span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="st">'map=~ags1+ags5+ags7</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="st">mav=~ags2+ags6+ags12</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="st">pap=~ags3+ags9+ags11</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="st">pav=~ags4+ags8+ags10</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="st">map ~~ 1*mav</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="st">pap ~~ 1*pav</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="st">'</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>h1_orthogonal.fit <span class="ot">&lt;-</span> <span class="fu">cfa</span>(</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">data  =</span> dat_ags,</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">model =</span> h1_orthogonal.definition</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare the goodness-of-fit statistics for the two models</span></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(h1.fit, h1_orthogonal.fit) <span class="sc">%&gt;%</span> </span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="table table-sm table-striped">
<colgroup>
<col style="width: 23%">
<col style="width: 3%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 14%">
<col style="width: 10%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">Df</th>
<th style="text-align: right;">AIC</th>
<th style="text-align: right;">BIC</th>
<th style="text-align: right;">Chisq</th>
<th style="text-align: right;">Chisq diff</th>
<th style="text-align: right;">Df diff</th>
<th style="text-align: right;">Pr(&gt;Chisq)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">h1.fit</td>
<td style="text-align: right;">48</td>
<td style="text-align: right;">14088.14</td>
<td style="text-align: right;">14209.28</td>
<td style="text-align: right;">328.3120</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">NA</td>
</tr>
<tr class="even">
<td style="text-align: left;">h1_orthogonal.fit</td>
<td style="text-align: right;">50</td>
<td style="text-align: right;">14096.44</td>
<td style="text-align: right;">14209.50</td>
<td style="text-align: right;">340.6065</td>
<td style="text-align: right;">12.29456</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">0.0021393</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Looks like the reduction in chi-squared goodness-of-fit is statistically significant when we force the within-skill factors to be perfectly correlated. So, according to the <span class="citation" data-cites="gorsuch1983">Gorsuch (<a href="#ref-gorsuch1983" role="doc-biblioref">1983</a>)</span> quote above, we can reject the null hypothesis that the within-skill factors are perfectly correlated. This gives a justification for continuing to distinguish between them as separate factors, and helps me make a believable claim that my posited factors are in fact different things.</p>
<p>Actually, I think another way we could have done this would be to just fit the model where we just define one big factor for ‘Mastery’ and one big factor for ‘Performance’. I tried this and it returned even worse fit, which means the extra parameters (the correlation parameters) are significantly improving fit in the pure h1 model.</p>
</section>
<section id="conclusion" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="conclusion">Conclusion</h3>
<p>All-in-all it seems like neither of these hypotheses do a great job. Sure, the ‘Performance’ factors have good convergent validity, and we see good discriminant validity between the ‘Performance’ and ‘Mastery’ factors, but the ‘Mastery’ factors don’t have great convergent validity and fitting a single monolithic ‘Mastery’ factor doesn’t improve things.</p>
<p>I can make a better model by dropping the measured ‘Mastery’ variables that aren’t having lots of their variance explained by the ‘Mastery’ factors, but this is contrary to the spirit of CFA. If I want to test a different hypothesis then I should collect a different sample.</p>
<p>For a nice template of a more formal presentation of the results of a CFA, see <span class="citation" data-cites="Brown2006">Brown (<a href="#ref-Brown2006" role="doc-biblioref">2006</a>)</span> chapter 4 appendix 3.</p>
</section>
</section>
<section id="example-2-biodiversity" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="example-2-biodiversity">Example 2: Biodiversity</h2>
<p>Here’s <a href="https://d9-wret.s3.us-west-2.amazonaws.com/assets/palladium/production/s3fs-public/atoms/files/SEM_09_2-Ex1_CFA_exercise.pdf">a fun example from the Wetland and Aquatic Research Center of the U.S. Geological Survey</a>: given counts of different types of animals, can we fit a convincing CFA model for ‘diversity’? In other words: is the correlation structure of all my counts of various types of animals consistent with the possibility that those counts are confounded by a single unobserved thing called ‘diversity’?</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>dat_raw <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">'data/grace/SEM_09_2-Ex1_CFA_exercise_data.csv'</span>)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>dat_clean <span class="ot">&lt;-</span> dat_raw <span class="sc">%&gt;%</span>  </span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>  janitor<span class="sc">::</span><span class="fu">clean_names</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="data-exploration-1" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="data-exploration-1">Data Exploration</h3>
<p>Just for fun let’s see if the relative proportions of the different animals varies between countries:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="do">### Proportions</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>dat_clean <span class="sc">%&gt;%</span> </span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">cols      =</span> <span class="sc">!</span><span class="fu">matches</span>(<span class="st">"^c"</span>),</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">names_to  =</span> <span class="st">"animal"</span>,</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">values_to =</span> <span class="st">"count"</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(country) <span class="sc">%&gt;%</span> </span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">total =</span> <span class="fu">sum</span>(count), </span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">prop  =</span> <span class="fu">round</span>(count <span class="sc">/</span> total, <span class="dv">2</span>)</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span> </span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="fu">aes</span>(<span class="at">x =</span> animal, <span class="at">y =</span> prop), <span class="at">stat =</span> <span class="st">"identity"</span>) <span class="sc">+</span> </span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span> </span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">angle =</span> <span class="dv">90</span>, <span class="at">vjust =</span> <span class="fl">0.5</span>, <span class="at">hjust=</span><span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>country)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="cfa_files/figure-html/unnamed-chunk-19-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The proportions are pretty stable. Finland seems like the weirdest one, and it isn’t even that weird.</p>
</section>
<section id="model-fitting-1" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="model-fitting-1">Model Fitting</h3>
<p>The hypothesis we want to test here is simply that all of these counts are confounded by a single unmeasured ‘biodiversity’ variable. This is straightforward to fit:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>h1.definition <span class="ot">&lt;-</span> </span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="st">'diversity =~ mammals + birds + amphibians + reptiles + beetles + butterflies'</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>h1.fit <span class="ot">&lt;-</span> <span class="fu">cfa</span>(</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">data  =</span> dat_clean <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>country) <span class="sc">%&gt;%</span> <span class="fu">scale</span>(),</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">model =</span> h1.definition</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>h1.summary <span class="ot">&lt;-</span> <span class="fu">summary</span>(h1.fit)</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>h1.summary</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6-12 ended normally after 23 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                        12

  Number of observations                            20

Model Test User Model:
                                                      
  Test statistic                                20.817
  Degrees of freedom                                 9
  P-value (Chi-square)                           0.013

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  diversity =~                                        
    mammals           1.000                           
    birds             0.825    0.277    2.978    0.003
    amphibians        1.115    0.260    4.281    0.000
    reptiles          0.780    0.279    2.793    0.005
    beetles           1.135    0.259    4.380    0.000
    butterflies       1.261    0.254    4.960    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .mammals           0.387    0.131    2.958    0.003
   .birds             0.566    0.184    3.073    0.002
   .amphibians        0.250    0.092    2.727    0.006
   .reptiles          0.608    0.197    3.089    0.002
   .beetles           0.224    0.085    2.645    0.008
   .butterflies       0.054    0.054    1.010    0.313
    diversity         0.563    0.278    2.025    0.043</code></pre>
</div>
</div>
<p>Let’s have a look at the same 4 goodness-of-fit measures we used in the previous example. We can bring them all together with a nice utility function:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="do">### Define a custom function</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>fit_measures <span class="ot">&lt;-</span> <span class="cf">function</span>(fit){</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>  summary <span class="ot">&lt;-</span> <span class="fu">summary</span>(fit, <span class="at">fit.measures =</span> <span class="cn">TRUE</span>, <span class="at">standardized =</span> <span class="cn">TRUE</span>)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>  res <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Chi-Squared</span></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">chi_squared =</span> <span class="fu">tibble</span>(</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">Test             =</span> <span class="st">"standard chi-squared"</span>,</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>      <span class="st">`</span><span class="at">DF</span><span class="st">`</span>             <span class="ot">=</span> summary<span class="sc">$</span>test<span class="sc">$</span>standard<span class="sc">$</span>df,</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>      <span class="st">`</span><span class="at">Test Statistic</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">round</span>(summary<span class="sc">$</span>test<span class="sc">$</span>standard<span class="sc">$</span>stat, <span class="dv">2</span>),</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>      <span class="st">`</span><span class="at">p-value</span><span class="st">`</span>        <span class="ot">=</span> summary<span class="sc">$</span>test<span class="sc">$</span>standard<span class="sc">$</span>pvalue) <span class="sc">%&gt;%</span> </span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>      <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="fu">everything</span>(), as.character)) <span class="sc">%&gt;%</span> </span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>      <span class="fu">pivot_longer</span>(<span class="fu">everything</span>()),</span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># RMSEA</span></span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">rmsea =</span> summary<span class="sc">$</span>fit <span class="sc">%&gt;%</span> </span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a>      <span class="fu">as_tibble</span>(<span class="at">rownames =</span> <span class="st">"stat"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>      <span class="fu">filter</span>(<span class="fu">str_detect</span>(stat, <span class="st">"rmsea"</span>)),</span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># CFI and TLI</span></span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">cfi_tli =</span> summary<span class="sc">$</span>fit <span class="sc">%&gt;%</span> </span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a>      <span class="fu">as_tibble</span>(<span class="at">rownames =</span> <span class="st">"stat"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a>      <span class="fu">filter</span>(<span class="fu">str_detect</span>(stat, <span class="st">"cfi|tli"</span>)) </span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb26-35"><a href="#cb26-35" aria-hidden="true" tabindex="-1"></a>  res</span>
<span id="cb26-36"><a href="#cb26-36" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb26-37"><a href="#cb26-37" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb26-38"><a href="#cb26-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-39"><a href="#cb26-39" aria-hidden="true" tabindex="-1"></a><span class="do">### Call the function, then send its outputs to clean tables</span></span>
<span id="cb26-40"><a href="#cb26-40" aria-hidden="true" tabindex="-1"></a><span class="fu">fit_measures</span>(h1.fit) <span class="sc">%&gt;%</span> </span>
<span id="cb26-41"><a href="#cb26-41" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb26-42"><a href="#cb26-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">map</span>(knitr<span class="sc">::</span>kable)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$chi_squared


|name           |value                |
|:--------------|:--------------------|
|Test           |standard chi-squared |
|DF             |9                    |
|Test Statistic |20.82                |
|p-value        |0.0134888288206897   |

$rmsea


|stat           |      value|
|:--------------|----------:|
|rmsea          | 0.25622117|
|rmsea.ci.lower | 0.11034617|
|rmsea.ci.upper | 0.40224444|
|rmsea.pvalue   | 0.01890337|

$cfi_tli


|stat |     value|
|:----|---------:|
|cfi  | 0.8695573|
|tli  | 0.7825955|</code></pre>
</div>
</div>
<p>The model isn’t fitting very well – Chi-Squared is highly statistically significant (we fail to reject the null hypothesis that there is residual variance left to explain), RMSEA is well above its conventional threshold, and CFI and TLI are both well below their conventional thresholds.</p>
</section>
<section id="modification-indexes" class="level3" data-number="2.0.1">
<h3 data-number="2.0.1" class="anchored" data-anchor-id="modification-indexes"><span class="header-section-number">2.0.1</span> Modification Indexes</h3>
<p>Here <span class="citation" data-cites="Grace">(<a href="#ref-Grace" role="doc-biblioref"><strong>Grace?</strong></a>)</span> introduces a new method for tweaking our CFA model to improve goodness of fit. The idea is that we can use fancy math to ask “if I took a certain fixed parameter from my model definition and allowed it to be freely estimated, how much would my model’s chi-squared goodness of fit change?” People like to take this estimated change in goodness-of-fit and call it a <strong>modification index.</strong> As <span class="citation" data-cites="Brown2006">Brown (<a href="#ref-Brown2006" role="doc-biblioref">2006</a>)</span> puts it:</p>
<blockquote class="blockquote">
<p>“The modification index reflects an approximation of how much the overall model <span class="math inline">\(χ^2\)</span> would decrease if the fixed or constrained parameter was freely estimated.”</p>
</blockquote>
<p>Apparently conventional cutoff for a ‘good’ modification index is 3.84. So to get some ideas on how we might improve our goodness-of-fit, let’s print out the modification indexes for each of the fixed parameters in the model and see which of them pass that threshold:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the estimated change in chi-squared for each fixed parameter</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="fu">modindices</span>(h1.fit) <span class="sc">%&gt;%</span> </span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Arrange them in order of modification index</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(mi)) <span class="sc">%&gt;%</span> </span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(lhs, op, rhs, mi) <span class="sc">%&gt;%</span> </span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th style="text-align: left;">lhs</th>
<th style="text-align: left;">op</th>
<th style="text-align: left;">rhs</th>
<th style="text-align: right;">mi</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">birds</td>
<td style="text-align: left;">~~</td>
<td style="text-align: left;">beetles</td>
<td style="text-align: right;">4.44</td>
</tr>
<tr class="even">
<td style="text-align: left;">birds</td>
<td style="text-align: left;">~~</td>
<td style="text-align: left;">amphibians</td>
<td style="text-align: right;">3.99</td>
</tr>
<tr class="odd">
<td style="text-align: left;">mammals</td>
<td style="text-align: left;">~~</td>
<td style="text-align: left;">butterflies</td>
<td style="text-align: right;">2.84</td>
</tr>
<tr class="even">
<td style="text-align: left;">beetles</td>
<td style="text-align: left;">~~</td>
<td style="text-align: left;">butterflies</td>
<td style="text-align: right;">2.78</td>
</tr>
<tr class="odd">
<td style="text-align: left;">mammals</td>
<td style="text-align: left;">~~</td>
<td style="text-align: left;">amphibians</td>
<td style="text-align: right;">2.31</td>
</tr>
<tr class="even">
<td style="text-align: left;">birds</td>
<td style="text-align: left;">~~</td>
<td style="text-align: left;">reptiles</td>
<td style="text-align: right;">2.05</td>
</tr>
<tr class="odd">
<td style="text-align: left;">amphibians</td>
<td style="text-align: left;">~~</td>
<td style="text-align: left;">butterflies</td>
<td style="text-align: right;">1.72</td>
</tr>
<tr class="even">
<td style="text-align: left;">birds</td>
<td style="text-align: left;">~~</td>
<td style="text-align: left;">butterflies</td>
<td style="text-align: right;">1.55</td>
</tr>
<tr class="odd">
<td style="text-align: left;">mammals</td>
<td style="text-align: left;">~~</td>
<td style="text-align: left;">reptiles</td>
<td style="text-align: right;">1.29</td>
</tr>
<tr class="even">
<td style="text-align: left;">mammals</td>
<td style="text-align: left;">~~</td>
<td style="text-align: left;">birds</td>
<td style="text-align: right;">1.20</td>
</tr>
<tr class="odd">
<td style="text-align: left;">amphibians</td>
<td style="text-align: left;">~~</td>
<td style="text-align: left;">beetles</td>
<td style="text-align: right;">0.58</td>
</tr>
<tr class="even">
<td style="text-align: left;">mammals</td>
<td style="text-align: left;">~~</td>
<td style="text-align: left;">beetles</td>
<td style="text-align: right;">0.38</td>
</tr>
<tr class="odd">
<td style="text-align: left;">reptiles</td>
<td style="text-align: left;">~~</td>
<td style="text-align: left;">butterflies</td>
<td style="text-align: right;">0.22</td>
</tr>
<tr class="even">
<td style="text-align: left;">reptiles</td>
<td style="text-align: left;">~~</td>
<td style="text-align: left;">beetles</td>
<td style="text-align: right;">0.15</td>
</tr>
<tr class="odd">
<td style="text-align: left;">amphibians</td>
<td style="text-align: left;">~~</td>
<td style="text-align: left;">reptiles</td>
<td style="text-align: right;">0.14</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Based on the operation symbol “~~”, it seems like all of the modification indexes correspond to residual correlations between observed variables. This teaches me something about CFA models! I guess in the typical CFA model we fix the residual correlations to 0? This helps me understand why the <a href="https://discourse.mc-stan.org/t/confirmatory-factor-analysis-using-brms/23139">Bayesian CFA model as implemented in <strong>brms</strong></a> specifies <code>rescor = FALSE</code> . I was confused about this!</p>
<p>Actually, I just realized <span class="citation" data-cites="gorsuch1983">Gorsuch (<a href="#ref-gorsuch1983" role="doc-biblioref">1983</a>)</span> already explained this to me! Think back to where he showed us the definition of the ‘Common Factor Model’:</p>
<p><span class="math inline">\(R_{vv} = PR_{ff}P' + U_{vv}\)</span></p>
<p>And remember how Gorsuch specified that <span class="math inline">\(U_{vv}\)</span> is assumed to be a diagonal matrix, IE the residual correlations is assumed to be uncorrelated for each variable. This is the whole thing about the ‘unique factors’, IE the error terms, of the linear models of each measured variable are gonna be uncorrelated. <a href="https://stats.oarc.ucla.edu/r/seminars/rcfa/">This recorded seminar and notes from UCLA</a> give a nice clear walkthrough of the notation in a slightly different form from <span class="citation" data-cites="gorsuch1983">Gorsuch (<a href="#ref-gorsuch1983" role="doc-biblioref">1983</a>)</span>.</p>
<p>From the DAGs perspective of CFA, assuming uncorrelated residuals sort of makes sense to me: if I want to convince you that my measured variables are all confounded by the same single unmeasured variable, then I think fixing the residual errors at 0 is a way of committing my model to the idea that there aren’t <em>other</em> unmeasured variables confounding certain of my measured guys. It is a strong assumption that, if it holds up, provides better evidence that my variables really truly are just confounded by a single unmeasured thing.</p>
<p>So I guess I could write out this standard CFA model in a more McElreath fashion like so:</p>
<p>$$ <span class="math display">\[\begin{align*}
\begin{bmatrix} \text{mammals}_i \\ \text{birds}_i \\ \text{amphibians}_i \\ \text{reptiles}_i \\ \text{beetles}_i \\ \end{bmatrix} &amp; \sim
\operatorname{MVNormal} \begin{pmatrix} \begin{bmatrix} \mu_{mammals} \\ \mu_{birds} \\ \mu_{amphibians} \\ \mu_{reptiles} \\ \mu_{beetles} \end{bmatrix}, \mathbf \Sigma\end{pmatrix}\\

\mu_{mammals} = \lambda_{mammals} F_i \\
\mu_{birds} = \lambda_{birds} F_i \\
\mu_{amphibians} = \lambda_{amphibians} F_i \\
\mu_{reptiles} = \lambda_{reptiles} F_i \\
\mu_{beetles} = \lambda_{beetles} F_i \\

\Sigma \begin{pmatrix}
\sigma_{mammals}&amp;0 &amp;0 &amp;0 &amp;0 \\
0 &amp; \sigma_{birds} &amp;0 &amp;0 &amp;0 \\
0 &amp; 0 &amp; \sigma_{amphibians} &amp;0 &amp;0 \\
0 &amp; 0 &amp; 0 &amp; \sigma_{reptiles} &amp;0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; \sigma_{beetles}
\end{pmatrix} \\
\end{align*}\]</span> $$</p>
<p>In human words: the observed counts of each of the 5 animal types are imagined to be drawn from a shared multivariate normal distribution. The mean of each dimension of that distribution is a linear function of a single shared factor, which we’re calling ‘biodiversity’. The variance of each dimension of that distribution is unique, and there is no covariance between the dimensions.</p>
<p>But now think back to our modification indexes: a few of them are saying that if we allow the residual covariances to be freely estimated rather than fixed at 0, then we can improve model fit by a whole lot. Specifically, if we allow the residual covariance between birds and beetles and/or between birds and amphibians to be freely estimated, then model fit as measured by the chi-squared statistic might be significantly improved. Here’s what the model is gonna look like now:</p>
<p>$$ <span class="math display">\[\begin{align*}
\begin{bmatrix} \text{mammals}_i \\ \text{birds}_i \\ \text{amphibians}_i \\ \text{reptiles}_i \\ \text{beetles}_i \\ \end{bmatrix} &amp; \sim
\operatorname{MVNormal} \begin{pmatrix} \begin{bmatrix} \mu_{mammals} \\ \mu_{birds} \\ \mu_{amphibians} \\ \mu_{reptiles} \\ \mu_{beetles} \end{bmatrix}, \mathbf \Sigma\end{pmatrix}\\

\mu_{mammals} = \lambda_{mammals} F_i \\
\mu_{birds} = \lambda_{birds} F_i \\
\mu_{amphibians} = \lambda_{amphibians} F_i \\
\mu_{reptiles} = \lambda_{reptiles} F_i \\
\mu_{beetles} = \lambda_{beetles} F_i \\

\Sigma \begin{pmatrix}
\sigma_{mammals}&amp;0 &amp;0 &amp;0 &amp;0 \\
0 &amp; \sigma_{birds} &amp;\theta_\text{b&amp;a} &amp;0 &amp;\theta_\text{b&amp;b} \\
0 &amp;\theta_\text{b&amp;a} &amp; \sigma_{amphibians} &amp;0 &amp;0 \\
0 &amp; 0 &amp; 0 &amp; \sigma_{reptiles} &amp;0 \\
0 &amp;\theta_\text{b&amp;b} &amp; 0 &amp; 0 &amp; \sigma_{beetles}
\end{pmatrix} \\
\end{align*}\]</span> $$</p>
<p>See how I’ve filled in the variance-covariance matrix of the likelihood to include a few more free parameters?</p>
<p>Actually, Grace proceeds by fitting two more models, one with each of these two candidate covariance parameters as freely fitting. Then he uses <code>anova()</code> to do a likelihood-ratio test for them. We can’t test all 3 models at once because models 2 and 3 aren’t nested with each other.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="do">### Letting the covariance between birds and beetles be freely estimated</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>h2.definition <span class="ot">&lt;-</span> </span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="st">'diversity =~ mammals + birds + amphibians + </span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="st">              reptiles + beetles + butterflies</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="st"> </span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="st"> birds ~~ beetles'</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>h2.fit <span class="ot">&lt;-</span> <span class="fu">cfa</span>(</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">data  =</span> dat_clean <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>country) <span class="sc">%&gt;%</span> <span class="fu">scale</span>(),</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">model =</span> h2.definition</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a><span class="do">### Letting the covariance between birds and amphibians be freely estimated</span></span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>h3.definition <span class="ot">&lt;-</span> </span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>  <span class="st">'diversity =~ mammals + birds + amphibians + </span></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a><span class="st">              reptiles + beetles + butterflies</span></span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a><span class="st"> </span></span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a><span class="st"> birds ~~ amphibians'</span></span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>h3.fit <span class="ot">&lt;-</span> <span class="fu">cfa</span>(</span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a> <span class="at">data  =</span> dat_clean <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>country) <span class="sc">%&gt;%</span> <span class="fu">scale</span>(),</span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a>  <span class="at">model =</span> h3.definition</span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(h1.fit, h2.fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Chi-Squared Difference Test

       Df    AIC    BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)  
h2.fit  8 270.81 283.76 16.013                                
h1.fit  9 273.62 285.56 20.817      4.804       1    0.02839 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(h1.fit, h3.fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Chi-Squared Difference Test

       Df    AIC    BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)   
h3.fit  8 267.72 280.67 12.924                                 
h1.fit  9 273.62 285.56 20.817     7.8934       1   0.004961 **
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>Looks like model H3 has the lowest AIC and the more significant improvement in chi-squared fit. So let’s continue working with that one in the following sections.</p>
</section>
<section id="validity" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="validity">Validity</h3>
<p>We can do the same 5 checks of validity we used in the previous ‘Mastery and Performance’ example. Let’s start with the big summary printout:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>summary.h3 <span class="ot">&lt;-</span> <span class="fu">summary</span>(h3.fit, <span class="at">fit.measures =</span> <span class="cn">TRUE</span>, <span class="at">standardized =</span> <span class="cn">TRUE</span>)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>summary.h3</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6-12 ended normally after 25 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                        13

  Number of observations                            20

Model Test User Model:
                                                      
  Test statistic                                12.923
  Degrees of freedom                                 8
  P-value (Chi-square)                           0.115

Model Test Baseline Model:

  Test statistic                               105.591
  Degrees of freedom                                15
  P-value                                        0.000

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    0.946
  Tucker-Lewis Index (TLI)                       0.898

Loglikelihood and Information Criteria:

  Loglikelihood user model (H0)               -120.861
  Loglikelihood unrestricted model (H1)       -114.400
                                                      
  Akaike (AIC)                                 267.723
  Bayesian (BIC)                               280.667
  Sample-size adjusted Bayesian (BIC)          240.592

Root Mean Square Error of Approximation:

  RMSEA                                          0.175
  90 Percent confidence interval - lower         0.000
  90 Percent confidence interval - upper         0.344
  P-value RMSEA &lt;= 0.05                          0.138

Standardized Root Mean Square Residual:

  SRMR                                           0.055

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  diversity =~                                                          
    mammals           1.000                               0.706    0.725
    birds             1.013    0.310    3.266    0.001    0.716    0.734
    amphibians        1.209    0.306    3.956    0.000    0.854    0.876
    reptiles          0.899    0.307    2.928    0.003    0.635    0.652
    beetles           1.264    0.301    4.196    0.000    0.893    0.916
    butterflies       1.261    0.301    4.187    0.000    0.891    0.914

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
 .birds ~~                                                              
   .amphibians       -0.245    0.094   -2.615    0.009   -0.245   -0.789

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .mammals           0.451    0.148    3.048    0.002    0.451    0.475
   .birds             0.438    0.152    2.877    0.004    0.438    0.461
   .amphibians        0.221    0.090    2.451    0.014    0.221    0.232
   .reptiles          0.546    0.177    3.087    0.002    0.546    0.575
   .beetles           0.153    0.061    2.506    0.012    0.153    0.161
   .butterflies       0.156    0.062    2.526    0.012    0.156    0.165
    diversity         0.499    0.267    1.866    0.062    1.000    1.000</code></pre>
</div>
</div>
<p>The factor loadings are all highly statistically significant, which is the first thing to check to make sure nothing is going horribly wrong.</p>
<p>The standardized loadings are pretty big as well, but not super great for ‘reptiles’. Also there’s a lot of variance in the loadings, which is evidence that my simple DAG of confounding may not be perfect – there are other unmeasured variables influencing some of my animal counts to different degrees. I mean of course there are, but the degree to which this is apparent based on the factor loadings undermines my claims to convergent validity.</p>
<p>Next we can look at the standardized residual variances. Some of them look great, and all but ‘reptiles’ pass the threshold of 0.5.</p>
<p>I could look at the ‘reliability’ statistics too, but can’t be bothered right now. Onwards to another example!</p>
</section>
</section>
<section id="example-3-happy-and-sad" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="example-3-happy-and-sad">Example 3: Happy and Sad</h2>
<section id="mtmm-and-error-theory" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="mtmm-and-error-theory">MTMM and ‘Error Theory’</h3>
<p>“multitrait–multimethod”</p>
<p>In the previous example we saw how we can sometimes improve model fit by freeing-up some of the residual covariance terms, rather than doing the typical thing of fixing them at 0. But this feels a bit icky to me – just pumping out some modification indexes and using that as a basis for opening up some free parameters feels pretty overfitty, because we don’t have a strong theory-driven reason for changing the model in that way.</p>
<p>But there <em>are</em> more kosher-feeling theory-driven reasons for freeing up some of the residual covariance parameters. Let’s talk about two of them: the first relates to convergent validity, the second relates to discriminant validity.</p>
<p>Here’s the first example: imagine I have a theory where there’s a thing called ‘exceptional leadership’, and it is made up of 3 unobservable features, like ‘self-confidence’, ‘oratorical skill’, and ‘robust compassionateness’. So I make up a survey where I ask 12 questions total, 4 per imagined factor. Then I fit a CFA model and find that it does a great job recreating the empirical variance-covariance matrix. There’s lots of great convergent validity between the questions I imagine to define the 3 factors. So I get published! But there’s a first problem: what if my within-factor variables are correlated not because they are cleanly confounded by ‘self-confidence’ (which is what I’m trying to convince you of), but instead because the within-factor survey questions are just worded in a really similar way, IE they are confounded by a latent factor we might call ‘wording similarity’? This possibility undermines my case for clean confounding.</p>
<p>Now the second example: imagine I do the same analysis described above, but I find my discriminant validity actually doesn’t look so hot, IE there are some high between-factor correlations. It is possible that this is just being caused by some of the variables used in different factors being confounded by their shared <strong>measurement approach,</strong> which creates a backdoor path between the factors.</p>
<p>As <span class="citation" data-cites="Brown2006">Brown (<a href="#ref-Brown2006" role="doc-biblioref">2006</a>)</span> puts it:</p>
<blockquote class="blockquote">
<p>“when each construct is assessed by the same measurement approach (e.g., observer rating), it cannot be determined how much of the observed overlap (i.e., factor correlations) is due to method effects as opposed to”true” covariance of the traits.”</p>
</blockquote>
<p>So we have these two risks:</p>
<ol type="1">
<li>Maybe some of my within-factor variables are confounded by method effects, which creates the <em>illusion</em> of convergent validity. If I go to publish my paper and someone raises this concern, then maybe I won’t get published! I’ll need to find a way to make my model control for possible method-confounding and <em>still</em> show good convergent validity.</li>
<li>Maybe some of my variables of different factors are confounded by method effects, so I don’t end up with great discriminant validity. This would be bad, but fitting a model that controls for method effects can maybe make things better.</li>
</ol>
<p>Fear not: there are two ways of adjusting the model to control for measurement confounding, thereby addressing the above risks.</p>
<ol type="1">
<li><p>Add method-specific factors to my model (to control for them in the linear model of each variable). <span class="citation" data-cites="Brown2006">Brown (<a href="#ref-Brown2006" role="doc-biblioref">2006</a>)</span> calls this a <strong>Correlated Methods Model</strong>;</p></li>
<li><p>Just freely fit the residual covariances between the observed variables that share a method. <span class="citation" data-cites="Brown2006">Brown (<a href="#ref-Brown2006" role="doc-biblioref">2006</a>)</span> calls this a <strong>Correlated Uniqueness Model.</strong> Because remember, ‘Uniqueness’ is just a fancy term for variable-specific residual variance.</p></li>
</ol>
<p>It’s all still just basic linear modelling, and trying to show that the model’s results are consistent with the DAG of clean confounding. By adding a method factors or allowing some of the error residuals to be freely fit, I’m controlling for sources of confounding that a reviewer might bring up as a concern, or that might be pulling down my discriminant validity.</p>
<p>Here’s how these approaches can improve convergent or divergent validity:</p>
<p><strong>Convergent validity:</strong> By adding method-factors to the model or freely fitting the residual covariances between the within-factor questions can help me make the case that “see, even when I allow for correlated errors due to <em>other</em> unobserved confounders (like common wording or common methods), the factors still do a good job recreating the empirical covariance structure, IE the loadings still look good, so my argument for <em>mostly</em> clean confounding is still reasonable.” I think this makes sense?</p>
<p><strong>Divergent validity:</strong> Maybe I can get better discriminant validity, IE reduce the between-factor correlations, by adding those method effects to the linear models, thereby controlling for them. I can do this either by literally adding in some new factors to represent each method, or just by allowing the residual covariances of like-method variables to be freely estimated.</p>
</section>
<section id="simulating-data-based-on-a-dag" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="simulating-data-based-on-a-dag">Simulating Data Based on a DAG</h3>
<p>Now let’s look at an example in detail. This example is taken from <span class="citation" data-cites="Brown2006">Brown (<a href="#ref-Brown2006" role="doc-biblioref">2006</a>)</span>, chapter 6.</p>
<p>Some researchers were curious about whether ‘happiness’ and ‘sadness’ are totally separate things vs two sides of a single shared spectrum. I guess the implication is that if they are totally separate things then I could be <a href="https://www.youtube.com/watch?v=U5oIvfraRrU">happy and sad at the same time</a>, whereas if they’re two sides of a spectrum then I can only ever be one or the other.</p>
<p>This feels like a good factor analysis question! I can collect a bunch of data that I think map to ‘happy’ and a bunch of other data that I think map to ‘sad’, fit a CFA, and see whether the two factors have discriminant validity.</p>
<p>This is exactly what <span class="citation" data-cites="Green-et-al-1993">al (<a href="#ref-Green-et-al-1993" role="doc-biblioref">n.d.</a>)</span> did. They collected a few columns each for ‘happy’ and ‘sad’, fit a factor model, and fit a CFA. Each within-factor column had its own measurement approach, but shared a measurement approach with one of the columns of the other factor. So we are at risk of our estimate of between-factor correlations being confounding due to shared measurement approach, which could be hurting my case for discriminant validity!</p>
<p>Here’s how we can show this situation in a DAG:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set DAG coordinates</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>dag_coords <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> <span class="fu">c</span>(</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">F1 =</span> <span class="dv">1</span>, </span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">F2 =</span> <span class="dv">1</span>,</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">H1 =</span> <span class="dv">2</span>,</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">H2 =</span> <span class="dv">2</span>,</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">H3 =</span> <span class="dv">2</span>,</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">S1 =</span> <span class="dv">2</span>,</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">S2 =</span> <span class="dv">2</span>,</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">S3 =</span> <span class="dv">2</span>,</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">M1 =</span> <span class="dv">3</span>,</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">M2 =</span> <span class="dv">3</span>,</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">M3 =</span> <span class="dv">3</span>),</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> <span class="fu">c</span>(</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">F1 =</span> <span class="fl">2.5</span>,</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">F2 =</span> <span class="fl">1.5</span>,</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">H1 =</span> <span class="fl">2.8</span>,</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">H2 =</span> <span class="fl">2.5</span>,</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">H3 =</span> <span class="fl">2.2</span>,</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">S1 =</span> <span class="fl">1.8</span>,</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">S2 =</span> <span class="fl">1.5</span>,</span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">S3 =</span> <span class="fl">1.2</span>,</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">M1 =</span> <span class="fl">2.6</span>,</span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>    <span class="at">M2 =</span> <span class="dv">2</span>,</span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a>    <span class="at">M3 =</span> <span class="fl">1.4</span></span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Set DAG relationships and aesthetics</span></span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a>measurement_confounding_dag <span class="ot">&lt;-</span> ggdag<span class="sc">::</span><span class="fu">dagify</span>(</span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a>  H1 <span class="sc">~</span> F1,</span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a>  H2 <span class="sc">~</span> F1,</span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a>  H3 <span class="sc">~</span> F1,</span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a>  S1 <span class="sc">~</span> F2,</span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a>  S2 <span class="sc">~</span> F2,</span>
<span id="cb35-37"><a href="#cb35-37" aria-hidden="true" tabindex="-1"></a>  S3 <span class="sc">~</span> F2,</span>
<span id="cb35-38"><a href="#cb35-38" aria-hidden="true" tabindex="-1"></a>  H1 <span class="sc">~</span> M1,</span>
<span id="cb35-39"><a href="#cb35-39" aria-hidden="true" tabindex="-1"></a>  S1 <span class="sc">~</span> M1,</span>
<span id="cb35-40"><a href="#cb35-40" aria-hidden="true" tabindex="-1"></a>  H2 <span class="sc">~</span> M2,</span>
<span id="cb35-41"><a href="#cb35-41" aria-hidden="true" tabindex="-1"></a>  S2 <span class="sc">~</span> M2,</span>
<span id="cb35-42"><a href="#cb35-42" aria-hidden="true" tabindex="-1"></a>  H3 <span class="sc">~</span> M3,</span>
<span id="cb35-43"><a href="#cb35-43" aria-hidden="true" tabindex="-1"></a>  S3 <span class="sc">~</span> M3,</span>
<span id="cb35-44"><a href="#cb35-44" aria-hidden="true" tabindex="-1"></a>  <span class="at">coords =</span> dag_coords</span>
<span id="cb35-45"><a href="#cb35-45" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> </span>
<span id="cb35-46"><a href="#cb35-46" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb35-47"><a href="#cb35-47" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy_dagitty</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb35-48"><a href="#cb35-48" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb35-49"><a href="#cb35-49" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb35-50"><a href="#cb35-50" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-51"><a href="#cb35-51" aria-hidden="true" tabindex="-1"></a>    <span class="at">node_colour =</span> <span class="fu">case_when</span>(</span>
<span id="cb35-52"><a href="#cb35-52" aria-hidden="true" tabindex="-1"></a>      <span class="fu">grepl</span>(<span class="st">"^F|M"</span>, name) <span class="sc">~</span> <span class="st">"latent"</span>,</span>
<span id="cb35-53"><a href="#cb35-53" aria-hidden="true" tabindex="-1"></a>      <span class="fu">grepl</span>(<span class="st">"^H|S"</span>, name) <span class="sc">~</span> <span class="st">"observed"</span></span>
<span id="cb35-54"><a href="#cb35-54" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb35-55"><a href="#cb35-55" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-56"><a href="#cb35-56" aria-hidden="true" tabindex="-1"></a>    <span class="at">edge_colour =</span> <span class="fu">case_when</span>(</span>
<span id="cb35-57"><a href="#cb35-57" aria-hidden="true" tabindex="-1"></a>      <span class="fu">grepl</span>(<span class="st">"^M"</span>, name) <span class="sc">&amp;</span> <span class="fu">grepl</span>(<span class="st">"1$"</span>, to) <span class="sc">~</span> <span class="st">"cornflower blue"</span>,</span>
<span id="cb35-58"><a href="#cb35-58" aria-hidden="true" tabindex="-1"></a>      <span class="fu">grepl</span>(<span class="st">"^M"</span>, name) <span class="sc">&amp;</span> <span class="fu">grepl</span>(<span class="st">"2$"</span>, to) <span class="sc">~</span> <span class="st">"#daed64"</span>,</span>
<span id="cb35-59"><a href="#cb35-59" aria-hidden="true" tabindex="-1"></a>      <span class="fu">grepl</span>(<span class="st">"^M"</span>, name) <span class="sc">&amp;</span> <span class="fu">grepl</span>(<span class="st">"3$"</span>, to) <span class="sc">~</span> <span class="st">"#ed7864"</span>,</span>
<span id="cb35-60"><a href="#cb35-60" aria-hidden="true" tabindex="-1"></a>      <span class="fu">grepl</span>(<span class="st">"^F"</span>, name)                   <span class="sc">~</span> <span class="st">"black"</span></span>
<span id="cb35-61"><a href="#cb35-61" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb35-62"><a href="#cb35-62" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb35-63"><a href="#cb35-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-64"><a href="#cb35-64" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the DAG</span></span>
<span id="cb35-65"><a href="#cb35-65" aria-hidden="true" tabindex="-1"></a>measurement_confounding_dag <span class="sc">%&gt;%</span></span>
<span id="cb35-66"><a href="#cb35-66" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y, <span class="at">xend =</span> xend, <span class="at">yend =</span> yend)) <span class="sc">+</span></span>
<span id="cb35-67"><a href="#cb35-67" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_dag_point</span>(<span class="fu">aes</span>(<span class="at">colour =</span> node_colour)) <span class="sc">+</span></span>
<span id="cb35-68"><a href="#cb35-68" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_colour_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"dark blue"</span>, <span class="st">"#edbc64"</span>)) <span class="sc">+</span> </span>
<span id="cb35-69"><a href="#cb35-69" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_dag_edges</span>(<span class="fu">aes</span>(<span class="at">edge_colour =</span> edge_colour)) <span class="sc">+</span></span>
<span id="cb35-70"><a href="#cb35-70" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_dag_text</span>() <span class="sc">+</span></span>
<span id="cb35-71"><a href="#cb35-71" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_void</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="cfa_files/figure-html/unnamed-chunk-25-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>See how the measurment effects M1, M2, and M3 each create a backdoor path between the two factors F1 and F2. So if I want to get better-seeming (and, under the DAG, more accurate) estimate of between-factor correlation, then I need to find a way to close those backdoor paths. The classic way to close these paths would be to condition on the measurement effects by adding them to the linear model, but I can’t directly do this because they are unmeasured. But, as discussed above, I can still sort of do it by adding them as factors to my CFA model, or by freely estimating residual correlation between the observed variables that share a measurement approach, which should work if my DAG is mostly accurate.</p>
<p>Unfortunately, the authors of this paper haven’t published their data. But we can take this as an opportunity to practice simulating a dataset with relationships implied by a DAG.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="do">### Simulate Data from the DAG</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed for replicable results</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">233</span>)</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Set sample size</span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">305</span></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the dataset</span></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>dat_fake <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># The factors are uncorrelated in reality, but</span></span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>  <span class="co"># will be confounded by the measurement effects!</span></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">F1 =</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">F2 =</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a>  <span class="co"># The measurement effects</span></span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">M1 =</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">M2 =</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">M3 =</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true" tabindex="-1"></a>  <span class="co"># The DAG says the measurements are fully determined by the latent factors and measurement effects</span></span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true" tabindex="-1"></a>  <span class="at">H1 =</span> .<span class="dv">8</span><span class="sc">*</span>F1 <span class="sc">+</span> <span class="fl">0.7</span><span class="sc">*</span>M1 <span class="sc">+</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, .<span class="dv">3</span>),</span>
<span id="cb36-24"><a href="#cb36-24" aria-hidden="true" tabindex="-1"></a>  <span class="at">H2 =</span> .<span class="dv">7</span><span class="sc">*</span>F1 <span class="sc">+</span> <span class="fl">0.7</span><span class="sc">*</span>M2 <span class="sc">+</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, .<span class="dv">3</span>),</span>
<span id="cb36-25"><a href="#cb36-25" aria-hidden="true" tabindex="-1"></a>  <span class="at">H3 =</span> .<span class="dv">9</span><span class="sc">*</span>F1 <span class="sc">+</span> <span class="fl">0.7</span><span class="sc">*</span>M3 <span class="sc">+</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, .<span class="dv">3</span>),</span>
<span id="cb36-26"><a href="#cb36-26" aria-hidden="true" tabindex="-1"></a>  <span class="at">S1 =</span> .<span class="dv">8</span><span class="sc">*</span>F2 <span class="sc">+</span> <span class="fl">0.7</span><span class="sc">*</span>M1 <span class="sc">+</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, .<span class="dv">3</span>),</span>
<span id="cb36-27"><a href="#cb36-27" aria-hidden="true" tabindex="-1"></a>  <span class="at">S2 =</span> .<span class="dv">7</span><span class="sc">*</span>F2 <span class="sc">+</span> <span class="fl">0.7</span><span class="sc">*</span>M2 <span class="sc">+</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, .<span class="dv">3</span>),</span>
<span id="cb36-28"><a href="#cb36-28" aria-hidden="true" tabindex="-1"></a>  <span class="at">S3 =</span> .<span class="dv">9</span><span class="sc">*</span>F2 <span class="sc">+</span> <span class="fl">0.7</span><span class="sc">*</span>M3 <span class="sc">+</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, .<span class="dv">3</span>) </span>
<span id="cb36-29"><a href="#cb36-29" aria-hidden="true" tabindex="-1"></a>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Fun! Now we have our fake data to play with. For starters, since we actually <em>do</em> have the values of the latent variables in our dataset, we can demonstrate how directly controlling for the measurement effects in a regression model can close the backdoor path between the factors.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">list</span>(</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lm</span>(H1 <span class="sc">~</span> S1, dat_fake), </span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lm</span>(H1 <span class="sc">~</span> S1 <span class="sc">+</span> M1, dat_fake)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> </span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">map</span>(broom<span class="sc">::</span>tidy) <span class="sc">%&gt;%</span> </span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">

<table class="kable_wrapper">
<tbody>
<tr>
<td>
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th style="text-align: left;">term</th>
<th style="text-align: right;">estimate</th>
<th style="text-align: right;">std.error</th>
<th style="text-align: right;">statistic</th>
<th style="text-align: right;">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">(Intercept)</td>
<td style="text-align: right;">0.0249271</td>
<td style="text-align: right;">0.0572795</td>
<td style="text-align: right;">0.435184</td>
<td style="text-align: right;">0.6637387</td>
</tr>
<tr class="even">
<td style="text-align: left;">S1</td>
<td style="text-align: right;">0.4555127</td>
<td style="text-align: right;">0.0491323</td>
<td style="text-align: right;">9.271137</td>
<td style="text-align: right;">0.0000000</td>
</tr>
</tbody>
</table>
</td>
<td>
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th style="text-align: left;">term</th>
<th style="text-align: right;">estimate</th>
<th style="text-align: right;">std.error</th>
<th style="text-align: right;">statistic</th>
<th style="text-align: right;">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">(Intercept)</td>
<td style="text-align: right;">0.0466841</td>
<td style="text-align: right;">0.0456881</td>
<td style="text-align: right;">1.0217995</td>
<td style="text-align: right;">0.3076936</td>
</tr>
<tr class="even">
<td style="text-align: left;">S1</td>
<td style="text-align: right;">-0.0137610</td>
<td style="text-align: right;">0.0528505</td>
<td style="text-align: right;">-0.2603763</td>
<td style="text-align: right;">0.7947509</td>
</tr>
<tr class="odd">
<td style="text-align: left;">M1</td>
<td style="text-align: right;">0.7636731</td>
<td style="text-align: right;">0.0577500</td>
<td style="text-align: right;">13.2237680</td>
<td style="text-align: right;">0.0000000</td>
</tr>
</tbody>
</table>
</td>
</tr>
</tbody>

</table>
</div>
</div>
<p>When we just do the simple regression of H1 on S1 we get a big effect with a highly statistically significant p-value, despite the fact that we <em>know</em> there’s no causal relationship there! But then when we include the confounding measurement effect in the model this effect vanishes in smoke.</p>
<p>That’s all well and good. But in reality we won’t have measurements of the latent variables, so we won’t be able to directly control for them. Thankfully, we have Factor Analysis. We can control for the measurement effects by estimating the residual correlation between each pair of variables that share a measurement effect. Since, under the DAG, the measurement effects are the only source of correlation between these variables, this should close the backdoor path, IE we should get unbiased estimates of the factor loadings.</p>
<p>BUT WHEN I REGRESS F1 ~ F2 I GET NO EFFECT, EVEN THOUGH THE DUMB VERSION OF THE CFA FINDS THEM TO BE CORRELATED. THIS PROBABLY REVEALS SOMETHING DEEP ABOUT FACTOR ANALYSIS THAT I DONT UNDERSTAND?</p>
<p>….@Brown2006 calls this an “error theory”…..</p>
<p>….</p>
</section>
<section id="correlated-uniqueness-model" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="correlated-uniqueness-model">Correlated Uniqueness Model</h3>
<p>To illustrate, we’ll fit 2 models: The first is a basic CFA model that just loads each measured variable on its corresponding factor. The second specifies that the residual correlation between the measurement-confounded variables should be freely estimated, IE not fixed at 0.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>basic.definition <span class="ot">&lt;-</span> </span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">'happy =~ H1 + H2 + H3</span></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="st">   sad =~ S1 + S2 + S3</span></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="st">   '</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>correlated_uniqueness.definition <span class="ot">&lt;-</span> </span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>  <span class="st">'happy =~ H1 + H2 + H3</span></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a><span class="st">   sad =~ S1 + S2 + S3</span></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a><span class="st">   </span></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a><span class="st">   H1 ~~ S1</span></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a><span class="st">   H2 ~~ S2</span></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a><span class="st">   H3 ~~ S3</span></span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a><span class="st">   '</span></span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>basic.fit <span class="ot">&lt;-</span> <span class="fu">cfa</span>(</span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> dat_fake <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="fu">matches</span>(<span class="st">"^(H|S)"</span>)),</span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">model =</span> basic.definition</span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a>correlated_uniqueness.fit <span class="ot">&lt;-</span> <span class="fu">cfa</span>(</span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> dat_fake <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="fu">matches</span>(<span class="st">"^(H|S)"</span>)),</span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">model =</span> correlated_uniqueness.definition</span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a>summary.basic.fit <span class="ot">&lt;-</span> <span class="fu">summary</span>(basic.fit, <span class="at">standardized =</span> <span class="cn">TRUE</span>)</span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true" tabindex="-1"></a>summary.correlated_uniqueness.fit <span class="ot">&lt;-</span> <span class="fu">summary</span>(correlated_uniqueness.fit, <span class="at">standardized =</span> <span class="cn">TRUE</span>)</span>
<span id="cb38-26"><a href="#cb38-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-27"><a href="#cb38-27" aria-hidden="true" tabindex="-1"></a>summary.basic.fit</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6-12 ended normally after 23 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                        13

  Number of observations                           305

Model Test User Model:
                                                      
  Test statistic                               802.905
  Degrees of freedom                                 8
  P-value (Chi-square)                           0.000

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  happy =~                                                              
    H1                1.000                               0.816    0.723
    H2                0.741    0.090    8.236    0.000    0.605    0.615
    H3                1.044    0.123    8.496    0.000    0.852    0.741
  sad =~                                                                
    S1                1.000                               0.906    0.778
    S2                0.818    0.079   10.302    0.000    0.742    0.704
    S3                0.980    0.093   10.522    0.000    0.888    0.752

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  happy ~~                                                              
    sad               0.236    0.060    3.934    0.000    0.319    0.319

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .H1                0.609    0.084    7.214    0.000    0.609    0.478
   .H2                0.601    0.062    9.662    0.000    0.601    0.621
   .H3                0.597    0.089    6.721    0.000    0.597    0.451
   .S1                0.537    0.077    6.989    0.000    0.537    0.395
   .S2                0.560    0.062    8.964    0.000    0.560    0.505
   .S3                0.604    0.078    7.726    0.000    0.604    0.434
    happy             0.667    0.114    5.860    0.000    1.000    1.000
    sad               0.822    0.119    6.886    0.000    1.000    1.000</code></pre>
</div>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>summary.correlated_uniqueness.fit</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6-12 ended normally after 47 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                        16

  Number of observations                           305

Model Test User Model:
                                                      
  Test statistic                                13.448
  Degrees of freedom                                 5
  P-value (Chi-square)                           0.020

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  happy =~                                                              
    H1                1.000                               0.738    0.669
    H2                0.915    0.055   16.787    0.000    0.676    0.657
    H3                1.157    0.066   17.625    0.000    0.854    0.755
  sad =~                                                                
    S1                1.000                               0.866    0.744
    S2                0.863    0.042   20.433    0.000    0.747    0.724
    S3                1.057    0.048   21.972    0.000    0.915    0.761

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
 .H1 ~~                                                                 
   .S1                0.551    0.061    9.007    0.000    0.551    0.866
 .H2 ~~                                                                 
   .S2                0.458    0.051    8.973    0.000    0.458    0.831
 .H3 ~~                                                                 
   .S3                0.501    0.062    8.133    0.000    0.501    0.868
  happy ~~                                                              
    sad               0.032    0.050    0.638    0.524    0.050    0.050

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .H1                0.672    0.070    9.641    0.000    0.672    0.552
   .H2                0.600    0.061    9.813    0.000    0.600    0.568
   .H3                0.550    0.071    7.769    0.000    0.550    0.430
   .S1                0.604    0.066    9.121    0.000    0.604    0.446
   .S2                0.507    0.053    9.538    0.000    0.507    0.476
   .S3                0.607    0.069    8.789    0.000    0.607    0.420
    happy             0.545    0.073    7.450    0.000    1.000    1.000
    sad               0.749    0.086    8.762    0.000    1.000    1.000</code></pre>
</div>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fit_measures</span>(basic.fit) <span class="sc">%&gt;%</span> </span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="at">caption =</span> <span class="st">"Basic Model"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">

<table class="kable_wrapper">
<caption>
Basic Model
</caption>
<tbody>
<tr>
<td>
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th style="text-align: left;">name</th>
<th style="text-align: left;">value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Test</td>
<td style="text-align: left;">standard chi-squared</td>
</tr>
<tr class="even">
<td style="text-align: left;">DF</td>
<td style="text-align: left;">8</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Test Statistic</td>
<td style="text-align: left;">802.9</td>
</tr>
<tr class="even">
<td style="text-align: left;">p-value</td>
<td style="text-align: left;">0</td>
</tr>
</tbody>
</table>
</td>
<td>
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th style="text-align: left;">stat</th>
<th style="text-align: right;">value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">rmsea</td>
<td style="text-align: right;">0.5707720</td>
</tr>
<tr class="even">
<td style="text-align: left;">rmsea.ci.lower</td>
<td style="text-align: right;">0.5377551</td>
</tr>
<tr class="odd">
<td style="text-align: left;">rmsea.ci.upper</td>
<td style="text-align: right;">0.6044999</td>
</tr>
<tr class="even">
<td style="text-align: left;">rmsea.pvalue</td>
<td style="text-align: right;">0.0000000</td>
</tr>
</tbody>
</table>
</td>
<td>
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th style="text-align: left;">stat</th>
<th style="text-align: right;">value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">cfi</td>
<td style="text-align: right;">0.3742618</td>
</tr>
<tr class="even">
<td style="text-align: left;">tli</td>
<td style="text-align: right;">-0.1732591</td>
</tr>
</tbody>
</table>
</td>
</tr>
</tbody>

</table>
</div>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fit_measures</span>(correlated_uniqueness.fit) <span class="sc">%&gt;%</span> </span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="at">caption =</span> <span class="st">"Correlated Uniqueness Model"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">

<table class="kable_wrapper">
<caption>
Correlated Uniqueness Model
</caption>
<tbody>
<tr>
<td>
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th style="text-align: left;">name</th>
<th style="text-align: left;">value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Test</td>
<td style="text-align: left;">standard chi-squared</td>
</tr>
<tr class="even">
<td style="text-align: left;">DF</td>
<td style="text-align: left;">5</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Test Statistic</td>
<td style="text-align: left;">13.45</td>
</tr>
<tr class="even">
<td style="text-align: left;">p-value</td>
<td style="text-align: left;">0.0195200124719597</td>
</tr>
</tbody>
</table>
</td>
<td>
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th style="text-align: left;">stat</th>
<th style="text-align: right;">value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">rmsea</td>
<td style="text-align: right;">0.07443086</td>
</tr>
<tr class="even">
<td style="text-align: left;">rmsea.ci.lower</td>
<td style="text-align: right;">0.02734066</td>
</tr>
<tr class="odd">
<td style="text-align: left;">rmsea.ci.upper</td>
<td style="text-align: right;">0.12377511</td>
</tr>
<tr class="even">
<td style="text-align: left;">rmsea.pvalue</td>
<td style="text-align: right;">0.16609111</td>
</tr>
</tbody>
</table>
</td>
<td>
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th style="text-align: left;">stat</th>
<th style="text-align: right;">value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">cfi</td>
<td style="text-align: right;">0.9933495</td>
</tr>
<tr class="even">
<td style="text-align: left;">tli</td>
<td style="text-align: right;">0.9800485</td>
</tr>
</tbody>
</table>
</td>
</tr>
</tbody>

</table>
</div>
</div>
<p>CLEAN UP THESE OUTPUTS! Here we see that under the basic model we have some moderate correlation between the <code>happy</code> and <code>sad</code> factors, which is a bit of a murky result: it doesn’t tell us one way or the other whether happiness and sadness are separate constructs I can feel together or two extremes of the same feeling. But under the correlated uniqueness model this correlation evaporates because we’ve controlled for the measurement effects, closing the backdoor path between <code>happy</code> and <code>sad</code>. This model also greatly improves goodness-of-fit, which makes sense because it better reflects the true data-generating process we coded up.</p>
<p>We also could have controlled for the measurement effects by including measurement factors, IE by adopting a ‘Correlated Methods Model’. I tried this but I actually I couldn’t get this model to converge, regardless of whether its method factors were correlated or uncorrelated (an ‘Uncorrelated Methods Model’. <span class="citation" data-cites="Brown2006">Brown (<a href="#ref-Brown2006" role="doc-biblioref">2006</a>)</span> actually mentions this as a common issue, and favours the Correlated Uniqueness Model for that reason. In his words:</p>
<blockquote class="blockquote">
<p>“an overriding drawback of the correlated methods model is that it is usually empirically underidentified. Consequently, a correlated methods solution will typically fail to converge. If it does converge, the solution will usually be associated with Heywood cases [negative variance estimates] and large standard errors”</p>
</blockquote>
<p>Now let’s consider the other case in which measurement effects might be hurting us: the case in which <em>within</em>-factor measurements are confounded by measurement effects. Here’s the DAG:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>dag_coords <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> <span class="fu">c</span>(</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">F1 =</span> <span class="dv">1</span>, </span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">F2 =</span> <span class="dv">1</span>,</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">H1 =</span> <span class="dv">2</span>,</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">H2 =</span> <span class="dv">2</span>,</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">H3 =</span> <span class="dv">2</span>,</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">S1 =</span> <span class="dv">2</span>,</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">S2 =</span> <span class="dv">2</span>,</span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">S3 =</span> <span class="dv">2</span>,</span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">M1 =</span> <span class="dv">3</span>,</span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">M2 =</span> <span class="dv">3</span>),</span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> <span class="fu">c</span>(</span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">F1 =</span> <span class="fl">2.5</span>,</span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">F2 =</span> <span class="fl">1.5</span>,</span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">H1 =</span> <span class="fl">2.8</span>,</span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">H2 =</span> <span class="fl">2.5</span>,</span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">H3 =</span> <span class="fl">2.2</span>,</span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">S1 =</span> <span class="fl">1.8</span>,</span>
<span id="cb44-20"><a href="#cb44-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">S2 =</span> <span class="fl">1.5</span>,</span>
<span id="cb44-21"><a href="#cb44-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">S3 =</span> <span class="fl">1.2</span>,</span>
<span id="cb44-22"><a href="#cb44-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">M1 =</span> <span class="fl">2.5</span>,</span>
<span id="cb44-23"><a href="#cb44-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">M2 =</span> <span class="fl">1.5</span></span>
<span id="cb44-24"><a href="#cb44-24" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb44-25"><a href="#cb44-25" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-26"><a href="#cb44-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-27"><a href="#cb44-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Set DAG relationships and aesthetics</span></span>
<span id="cb44-28"><a href="#cb44-28" aria-hidden="true" tabindex="-1"></a>measurement_confounding_dag <span class="ot">&lt;-</span> ggdag<span class="sc">::</span><span class="fu">dagify</span>(</span>
<span id="cb44-29"><a href="#cb44-29" aria-hidden="true" tabindex="-1"></a>  H3 <span class="sc">~</span> F1,</span>
<span id="cb44-30"><a href="#cb44-30" aria-hidden="true" tabindex="-1"></a>  S2 <span class="sc">~</span> F2,</span>
<span id="cb44-31"><a href="#cb44-31" aria-hidden="true" tabindex="-1"></a>  H1 <span class="sc">~</span> M1,</span>
<span id="cb44-32"><a href="#cb44-32" aria-hidden="true" tabindex="-1"></a>  H2 <span class="sc">~</span> M1,</span>
<span id="cb44-33"><a href="#cb44-33" aria-hidden="true" tabindex="-1"></a>  H3 <span class="sc">~</span> M1,</span>
<span id="cb44-34"><a href="#cb44-34" aria-hidden="true" tabindex="-1"></a>  S1 <span class="sc">~</span> M2,</span>
<span id="cb44-35"><a href="#cb44-35" aria-hidden="true" tabindex="-1"></a>  S2 <span class="sc">~</span> M2,</span>
<span id="cb44-36"><a href="#cb44-36" aria-hidden="true" tabindex="-1"></a>  S3 <span class="sc">~</span> M2,</span>
<span id="cb44-37"><a href="#cb44-37" aria-hidden="true" tabindex="-1"></a>  <span class="at">coords =</span> dag_coords</span>
<span id="cb44-38"><a href="#cb44-38" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> </span>
<span id="cb44-39"><a href="#cb44-39" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb44-40"><a href="#cb44-40" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy_dagitty</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb44-41"><a href="#cb44-41" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb44-42"><a href="#cb44-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb44-43"><a href="#cb44-43" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb44-44"><a href="#cb44-44" aria-hidden="true" tabindex="-1"></a>    <span class="at">node_colour =</span> <span class="fu">case_when</span>(</span>
<span id="cb44-45"><a href="#cb44-45" aria-hidden="true" tabindex="-1"></a>      <span class="fu">grepl</span>(<span class="st">"^F|M"</span>, name) <span class="sc">~</span> <span class="st">"latent"</span>,</span>
<span id="cb44-46"><a href="#cb44-46" aria-hidden="true" tabindex="-1"></a>      <span class="fu">grepl</span>(<span class="st">"^H|S"</span>, name) <span class="sc">~</span> <span class="st">"observed"</span></span>
<span id="cb44-47"><a href="#cb44-47" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb44-48"><a href="#cb44-48" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb44-49"><a href="#cb44-49" aria-hidden="true" tabindex="-1"></a>    <span class="at">edge_colour =</span> <span class="fu">case_when</span>(</span>
<span id="cb44-50"><a href="#cb44-50" aria-hidden="true" tabindex="-1"></a>      <span class="fu">grepl</span>(<span class="st">"M1"</span>, name)  <span class="sc">~</span> <span class="st">"cornflower blue"</span>,</span>
<span id="cb44-51"><a href="#cb44-51" aria-hidden="true" tabindex="-1"></a>      <span class="fu">grepl</span>(<span class="st">"M2"</span>, name) <span class="sc">~</span> <span class="st">"#ed7864"</span>,</span>
<span id="cb44-52"><a href="#cb44-52" aria-hidden="true" tabindex="-1"></a>      <span class="fu">grepl</span>(<span class="st">"^XX"</span>, name) <span class="sc">&amp;</span> <span class="fu">grepl</span>(<span class="st">"3$"</span>, to) <span class="sc">~</span> <span class="st">"#ed7864"</span>,</span>
<span id="cb44-53"><a href="#cb44-53" aria-hidden="true" tabindex="-1"></a>      <span class="fu">grepl</span>(<span class="st">"^F"</span>, name)                   <span class="sc">~</span> <span class="st">"black"</span></span>
<span id="cb44-54"><a href="#cb44-54" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb44-55"><a href="#cb44-55" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb44-56"><a href="#cb44-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-57"><a href="#cb44-57" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the DAG</span></span>
<span id="cb44-58"><a href="#cb44-58" aria-hidden="true" tabindex="-1"></a>measurement_confounding_dag <span class="sc">%&gt;%</span></span>
<span id="cb44-59"><a href="#cb44-59" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y, <span class="at">xend =</span> xend, <span class="at">yend =</span> yend)) <span class="sc">+</span></span>
<span id="cb44-60"><a href="#cb44-60" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_dag_point</span>(<span class="fu">aes</span>(<span class="at">colour =</span> node_colour)) <span class="sc">+</span></span>
<span id="cb44-61"><a href="#cb44-61" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_colour_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"dark blue"</span>, <span class="st">"#edbc64"</span>)) <span class="sc">+</span> </span>
<span id="cb44-62"><a href="#cb44-62" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_dag_edges</span>(<span class="fu">aes</span>(<span class="at">edge_colour =</span> edge_colour)) <span class="sc">+</span></span>
<span id="cb44-63"><a href="#cb44-63" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_dag_text</span>() <span class="sc">+</span></span>
<span id="cb44-64"><a href="#cb44-64" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_void</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="cfa_files/figure-html/unnamed-chunk-29-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>This is the ‘true’ data-generating process we’ll be simulating data from in a moment. Notice that even though the researcher (who can’t see this DAG) might think that the unobseved factor causally influences all 3 measured variables, the reality is that each factor only influences one of the measured variables. However, the purported within-factor variables are confounded by measurement method.</p>
<p>Let’s simulate the data and analyze:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed for replicable results</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">233</span>)</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set sample size</span></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">30000</span></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the dataset</span></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>dat_fake <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Create some uncorrelated factors</span></span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">F1 =</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">F2 =</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Create some measurement effects</span></span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">M1 =</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">M2 =</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb45-18"><a href="#cb45-18" aria-hidden="true" tabindex="-1"></a>  <span class="co"># The DAG says only H3 and S2 are influenced by the factors, but all variables are influenced by a measurement effect.</span></span>
<span id="cb45-19"><a href="#cb45-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">H1 =</span> <span class="fl">0.7</span><span class="sc">*</span>M1 <span class="sc">+</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, .<span class="dv">3</span>),</span>
<span id="cb45-20"><a href="#cb45-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">H2 =</span> <span class="fl">0.8</span><span class="sc">*</span>M1 <span class="sc">+</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, .<span class="dv">3</span>),</span>
<span id="cb45-21"><a href="#cb45-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">H3 =</span> <span class="fl">0.9</span><span class="sc">*</span>F1 <span class="sc">+</span> <span class="fl">0.8</span><span class="sc">*</span>M1 <span class="sc">+</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, .<span class="dv">3</span>),</span>
<span id="cb45-22"><a href="#cb45-22" aria-hidden="true" tabindex="-1"></a>  <span class="at">S1 =</span> <span class="fl">0.7</span><span class="sc">*</span>M2 <span class="sc">+</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, .<span class="dv">3</span>),</span>
<span id="cb45-23"><a href="#cb45-23" aria-hidden="true" tabindex="-1"></a>  <span class="at">S2 =</span> <span class="fl">0.7</span><span class="sc">*</span>F2 <span class="sc">+</span> <span class="fl">0.8</span><span class="sc">*</span>M2 <span class="sc">+</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, .<span class="dv">3</span>),</span>
<span id="cb45-24"><a href="#cb45-24" aria-hidden="true" tabindex="-1"></a>  <span class="at">S3 =</span> <span class="fl">0.7</span><span class="sc">*</span>M2 <span class="sc">+</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, .<span class="dv">3</span>) </span>
<span id="cb45-25"><a href="#cb45-25" aria-hidden="true" tabindex="-1"></a>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>First let’s fit a basic naive CFA model that does the standard thing of keeping the covariances between variables fixed at 0. Based on the DAG, we should expect this model to return a strong (publishable) but misleading answer – it will notice the correlation between variables that are considered within-factor under our hypothesis, and say ‘wow so correlated, that’s consistent with them being <em>caused</em> by that factor’. But we know this is wrong: their correlation is simply driven by the shared measurement method:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>basic.definition <span class="ot">&lt;-</span> </span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">'happy =~ H1 + H2 + H3</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="st">   sad =~ S1 + S2 + S3</span></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="st">   '</span></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>basic.fit <span class="ot">&lt;-</span> <span class="fu">cfa</span>(</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> dat_fake,</span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">model =</span> basic.definition</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(basic.fit, <span class="at">standardized =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6-12 ended normally after 25 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                        13

  Number of observations                         30000

Model Test User Model:
                                                      
  Test statistic                                 7.086
  Degrees of freedom                                 8
  P-value (Chi-square)                           0.527

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  happy =~                                                              
    H1                1.000                               0.705    0.920
    H2                1.141    0.006  196.951    0.000    0.804    0.936
    H3                1.142    0.009  129.172    0.000    0.805    0.646
  sad =~                                                                
    S1                1.000                               0.696    0.917
    S2                1.142    0.008  151.721    0.000    0.795    0.722
    S3                1.004    0.005  206.981    0.000    0.699    0.922

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  happy ~~                                                              
    sad              -0.002    0.003   -0.765    0.444   -0.005   -0.005

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .H1                0.090    0.002   42.749    0.000    0.090    0.154
   .H2                0.091    0.003   34.103    0.000    0.091    0.124
   .H3                0.903    0.008  115.595    0.000    0.903    0.582
   .S1                0.091    0.002   49.153    0.000    0.091    0.158
   .S2                0.581    0.005  110.971    0.000    0.581    0.479
   .S3                0.086    0.002   46.614    0.000    0.086    0.150
    happy             0.497    0.005   96.783    0.000    1.000    1.000
    sad               0.484    0.005   98.040    0.000    1.000    1.000</code></pre>
</div>
</div>
<p>And there you have it – just as foretold, we have super strong factor loadings for all the variables, even those that are not actually causally influenced by the factor! So it may <em>look</em> like I have strong convergent validity, but hopefully if we try to publish this, a reviewer will raise the possibility that these correlations are confounded by measurement effects.</p>
<p>Now I’m going to try closing the backdoor paths between the non-factor-caused variables by allowing the model to learn the covariances, thereby hopefully controlling for unobserved sources of confounding (like the measurement effect). If the loadings stay strong, then my claims to convergent validity are more reasonable.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>correlated_uniqueness.definition <span class="ot">&lt;-</span> </span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">'happy =~ H1 + H2 + H3</span></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="st">   sad   =~ S1 + S2 + S3</span></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a><span class="st">   </span></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a><span class="st">   H1 ~~ H2</span></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a><span class="st">   H1 ~~ H3</span></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a><span class="st">   H2 ~~ H3</span></span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a><span class="st">   S1 ~~ S2</span></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a><span class="st">   S1 ~~ S3</span></span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a><span class="st">   S2 ~~ S3</span></span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a><span class="st">   '</span></span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a>correlated_uniqueness.fit <span class="ot">&lt;-</span> <span class="fu">cfa</span>(</span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> dat_fake,</span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">model =</span> correlated_uniqueness.definition</span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in lav_model_vcov(lavmodel = lavmodel, lavsamplestats = lavsamplestats, : lavaan WARNING:
    Could not compute standard errors! The information matrix could
    not be inverted. This may be a symptom that the model is not
    identified.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in lav_object_post_check(object): lavaan WARNING: some estimated ov
variances are negative</code></pre>
</div>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(correlated_uniqueness.fit, <span class="at">standardized =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6-12 ended normally after 593 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                        19

  Number of observations                         30000

Model Test User Model:
                                                      
  Test statistic                                 0.453
  Degrees of freedom                                 2
  P-value (Chi-square)                           0.797

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  happy =~                                                              
    H1                1.000                               0.922    1.203
    H2                0.712       NA                      0.656    0.764
    H3               -2.144       NA                     -1.976   -1.587
  sad =~                                                                
    S1                1.000                               0.571    0.752
    S2                0.393       NA                      0.224    0.204
    S3                2.194       NA                      1.252    1.653

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
 .H1 ~~                                                                 
   .H2               -0.038       NA                     -0.038   -0.135
   .H3                2.388       NA                      2.388    3.038
 .H2 ~~                                                                 
   .H3                1.944       NA                      1.944    2.288
 .S1 ~~                                                                 
   .S2                0.425       NA                      0.425    0.789
   .S3               -0.228       NA                     -0.228   -0.459
 .S2 ~~                                                                 
   .S3                0.274       NA                      0.274    0.255
  happy ~~                                                              
    sad              -0.001       NA                     -0.002   -0.002

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .H1               -0.263       NA                     -0.263   -0.447
   .H2                0.307       NA                      0.307    0.416
   .H3               -2.353       NA                     -2.353   -1.517
   .S1                0.250       NA                      0.250    0.434
   .S2                1.162       NA                      1.162    0.958
   .S3               -0.994       NA                     -0.994   -1.731
    happy             0.850       NA                      1.000    1.000
    sad               0.326       NA                      1.000    1.000</code></pre>
</div>
</div>
<p>Uh-oh…the model failed to converge :(. Apparently this is a common thing with CFA models that try to learn the correlation between within-factor variables – the parameters are non-identified because you’re asking the model to learn their correlation simultaneously in two different parameters: the factor loading and the covariance parameter. <a href="https://stackoverflow.com/questions/44114501/model-identification-in-lavaan-for-r">This Stack Exchange thread</a> explains it nicely.</p>
</section>
</section>
<section id="example-4-school-grades" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="example-4-school-grades"><span class="header-section-number">2.1</span> Example 4: School Grades</h2>
<p>Now let’s see an example taken from the Advanced Statistical Computing people at UCLA. The dataset comes from the High School and Beyond project, which tracks academic performance in the US along with some data about students.</p>
<p>As usual with CFA, my goal here is to convince somebody that certain of my variables are strongly confounded by a shared unmeasured (and unmeasurable) variable. Specifically, I want to convince them that four student grades, namely reading, writing, mathematics and science, are confounded by a shared unmeasurable variable called ‘academic performance’. Great.</p>
<section id="measurement-invariance" class="level3" data-number="2.1.1">
<h3 data-number="2.1.1" class="anchored" data-anchor-id="measurement-invariance"><span class="header-section-number">2.1.1</span> Measurement Invariance</h3>
<p>But there’s a problem: a reviewer might ask if it really makes sense to think of ‘academic performance’ as being the same thing for boy-labelled and girl-labelled people. So if I want to convince that reviewer of my usual ‘simple confounding’ DAG structure, then I’ll need to answer a few extra questions:</p>
<ol type="1">
<li>Does the model fit equally well when I fit it on the group-level sub-datasets in isolation?</li>
<li>Are the data consistent with the idea that the different groups are actually confounded by the same latent thing? People like to test this by making sure the loadings are pretty similar across the models for the different groups. If the loadings are similar then I can can say they are ‘invariant’.</li>
<li>Do the data themselves actually have stable properties across groups? If not, then even if the model fits the data equally well for different groups or at different times, and even if the loadings are pretty similar across groups, then that’s actually a bad thing if I want to convince you that the factor is the same thing for different groups! People generally just like to check this by including an intercept term in the linear regression for each variable in the CFA model. If these intercepts are pretty similar across groups or across timepoints then we can say they are ‘invariant’.</li>
</ol>
<p>When I’m worrying about these sorts of things, I am worrying about what people like to call <strong>measurement invariance.</strong> As <span class="citation" data-cites="Brown2006">Brown (<a href="#ref-Brown2006" role="doc-biblioref">2006</a>)</span> puts it, the big idea with ‘Measurement Invariance’ is the worry that:</p>
<blockquote class="blockquote">
<p>“if either the loading or the intercept [of a variable across groups] is noninvariant, [then the model thinks] the observed values of the indicator will differ between groups at a given level of the latent variable.”</p>
</blockquote>
<p>We definitely don’t want a model that thinks that, because it is not consistent with what I’m trying to convince my reviewers of: that the observed variables are merely puppets, confounded by the same unmeasured variable in the same way across all groups or timepoints.</p>
</section>
<section id="multigroup-cfa" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="multigroup-cfa">Multigroup CFA</h3>
<p>There are a few classical workflows for dealing with measurement invariance, which @Brown2006 details in chapter 7 of his book. But he recommends something called ‘Multigroup CFA’, so let’s go with that. We’ll be following the workflow for this type of model as presented in that chapter.</p>
<section id="configural-invariance" class="level4" data-number="2.1.1.1">
<h4 data-number="2.1.1.1" class="anchored" data-anchor-id="configural-invariance"><span class="header-section-number">2.1.1.1</span> ‘Configural’ Invariance</h4>
<p>The first step is to fit the model separately for the two groups in isolation and see whether they both have OK goodness of fit. So let’s split the data into two subsets based on the group we’re interested in, and then define the <strong>lavaan</strong> models with the usual syntax, but specifying that want the linear model of each variable to also have an intercept, as explained above:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="do">### Load the data</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">'data/ucla/hsbdemo.csv'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Rows: 200 Columns: 13
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
chr (5): female, ses, schtyp, prog, honors
dbl (8): id, read, write, math, science, socst, awards, cid

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="do">### Load the data again but in split format, for what is to come.</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>dat_split <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">boys  =</span> dat <span class="sc">%&gt;%</span> <span class="fu">filter</span>(female <span class="sc">==</span> <span class="st">"female"</span>),</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">girls =</span> dat <span class="sc">%&gt;%</span> <span class="fu">filter</span>(female <span class="sc">==</span> <span class="st">"male"</span>)</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a><span class="do">### Define the basic CFA model</span></span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a>onefac <span class="ot">&lt;-</span> <span class="st">'f1  =~ read + write + math + science'</span></span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a><span class="do">### Fit the model separately for each group</span></span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a>onefac_models <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">onefac_boys  =</span> <span class="fu">cfa</span>(onefac, <span class="at">data =</span> dat_split<span class="sc">$</span>boys, <span class="at">meanstructure =</span> <span class="cn">TRUE</span>),</span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">onefac_girls =</span> <span class="fu">cfa</span>(onefac, <span class="at">data =</span> dat_split<span class="sc">$</span>girls, <span class="at">meanstructure =</span> <span class="cn">TRUE</span>) </span>
<span id="cb55-14"><a href="#cb55-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb55-15"><a href="#cb55-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-16"><a href="#cb55-16" aria-hidden="true" tabindex="-1"></a><span class="do">### Gaze at the parameter estimates</span></span>
<span id="cb55-17"><a href="#cb55-17" aria-hidden="true" tabindex="-1"></a>onefac_models <span class="sc">%&gt;%</span> <span class="fu">map</span>(summary, <span class="at">standardized =</span> <span class="cn">TRUE</span>, <span class="at">fit.measures =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$onefac_boys
lavaan 0.6-12 ended normally after 46 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                        12

  Number of observations                           109

Model Test User Model:
                                                      
  Test statistic                                 1.903
  Degrees of freedom                                 2
  P-value (Chi-square)                           0.386

Model Test Baseline Model:

  Test statistic                               230.890
  Degrees of freedom                                 6
  P-value                                        0.000

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    1.000
  Tucker-Lewis Index (TLI)                       1.001

Loglikelihood and Information Criteria:

  Loglikelihood user model (H0)              -1463.504
  Loglikelihood unrestricted model (H1)      -1462.553
                                                      
  Akaike (AIC)                                2951.009
  Bayesian (BIC)                              2983.305
  Sample-size adjusted Bayesian (BIC)         2945.387

Root Mean Square Error of Approximation:

  RMSEA                                          0.000
  90 Percent confidence interval - lower         0.000
  90 Percent confidence interval - upper         0.187
  P-value RMSEA &lt;= 0.05                          0.479

Standardized Root Mean Square Residual:

  SRMR                                           0.013

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  f1 =~                                                                 
    read              1.000                               8.006    0.800
    write             0.801    0.091    8.769    0.000    6.414    0.792
    math              0.985    0.102    9.621    0.000    7.889    0.866
    science           0.863    0.102    8.453    0.000    6.912    0.768

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .read             51.734    0.959   53.949    0.000   51.734    5.167
   .write            54.991    0.775   70.911    0.000   54.991    6.792
   .math             52.394    0.872   60.052    0.000   52.394    5.752
   .science          50.697    0.862   58.830    0.000   50.697    5.635
    f1                0.000                               0.000    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .read             36.133    6.426    5.623    0.000   36.133    0.360
   .write            24.410    4.271    5.716    0.000   24.410    0.372
   .math             20.736    4.693    4.419    0.000   20.736    0.250
   .science          33.165    5.555    5.971    0.000   33.165    0.410
    f1               64.099   13.331    4.808    0.000    1.000    1.000


$onefac_girls
lavaan 0.6-12 ended normally after 44 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                        12

  Number of observations                            91

Model Test User Model:
                                                      
  Test statistic                                 0.719
  Degrees of freedom                                 2
  P-value (Chi-square)                           0.698

Model Test Baseline Model:

  Test statistic                               176.055
  Degrees of freedom                                 6
  P-value                                        0.000

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    1.000
  Tucker-Lewis Index (TLI)                       1.023

Loglikelihood and Information Criteria:

  Loglikelihood user model (H0)              -1275.517
  Loglikelihood unrestricted model (H1)      -1275.157
                                                      
  Akaike (AIC)                                2575.033
  Bayesian (BIC)                              2605.164
  Sample-size adjusted Bayesian (BIC)         2567.288

Root Mean Square Error of Approximation:

  RMSEA                                          0.000
  90 Percent confidence interval - lower         0.000
  90 Percent confidence interval - upper         0.153
  P-value RMSEA &lt;= 0.05                          0.750

Standardized Root Mean Square Residual:

  SRMR                                           0.009

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  f1 =~                                                                 
    read              1.000                               8.531    0.816
    write             0.954    0.119    7.983    0.000    8.137    0.794
    math              0.863    0.113    7.663    0.000    7.361    0.766
    science           0.999    0.124    8.031    0.000    8.521    0.798

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .read             52.824    1.095   48.227    0.000   52.824    5.056
   .write            50.121    1.074   46.653    0.000   50.121    4.891
   .math             52.945    1.008   52.548    0.000   52.945    5.508
   .science          53.231    1.119   47.577    0.000   53.231    4.987
    f1                0.000                               0.000    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .read             36.404    7.769    4.686    0.000   36.404    0.333
   .write            38.825    7.775    4.993    0.000   38.825    0.370
   .math             38.197    7.210    5.298    0.000   38.197    0.413
   .science          41.300    8.365    4.937    0.000   41.300    0.363
    f1               72.774   16.251    4.478    0.000    1.000    1.000</code></pre>
</div>
</div>
<p>The first thing I notice is that the models don’t fit great. Indeed, these are the first significant chi-squared test p-values I’ve ever seen in all of these examples, indicating that the results are consistent with there being lots of residual variance the model hasn’t accounted for. But the UCLA people don’t comment on this, so I guess neither will I.</p>
<p>Next I notice that the factor loadings and residual variances look pretty good and consistent across the groups. This is suggestive of what people unfortunately like to call <strong>Configural Invariance</strong>, which just means the same model fits to the groups pretty much the same in isolation. As <span class="citation" data-cites="Brown">(<a href="#ref-Brown" role="doc-biblioref"><strong>Brown?</strong></a>)</span> puts it:</p>
<blockquote class="blockquote">
<p>“equal form [aka ‘configural invariance’ is when] the number of factors and pattern of indicator–factor loadings are identical across groups)”</p>
</blockquote>
<p>The main exception to this I notice in the above model is that there’s a bunch more residual variance in ‘math’ for boys than for girls. So maybe that’s something to look out for.</p>
<p>The next thing to do is fit the exact same model as above, but in a slightly fancier syntax. Specifically, we’re gonna fit it with a single command so that it can serve as the best-fitting big daddy model when we start constraining parameters to be equal across groups and doing the nested likelihood ratio test stuff we’ll be doing later. I think this is literally the exact same thing as the previous model but it serves that LRT-daddy role by giving us a single chi-squared goodness-of-fit statistic for the whole dataset, rather than one for each group in isolation. Honestly I’m not sure why both <span class="citation" data-cites="Brown">(<a href="#ref-Brown" role="doc-biblioref"><strong>Brown?</strong></a>)</span> and UCLA have us fit the previous model at all.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>configural.fit <span class="ot">&lt;-</span> <span class="fu">cfa</span>(onefac, <span class="at">data =</span> dat, <span class="at">group =</span> <span class="st">"female"</span>, <span class="at">meanstructure =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Notice how we just did the exact same thing as before, but we used the full dataset instead of the split sub-datasets, and we used <code>cfa()</code> function’s <code>group</code> parameter to tell the model we’re interested in group stuff. I’m not actually gonna print the outputs for this model because the loadings and residual variances are the exact same for the previous model, and the single chi-squared statistic is simply the sum of the chi-squared statistics from the previous model.</p>
</section>
<section id="metric-weak-invariance" class="level4" data-number="2.1.1.2">
<h4 data-number="2.1.1.2" class="anchored" data-anchor-id="metric-weak-invariance"><span class="header-section-number">2.1.1.2</span> ‘Metric’ / ‘Weak’ Invariance</h4>
<p>Next we’re gonna want to see if goodness-of-fit isn’t significantly reduced when we constrain the loading for each variable to be equal in both models. The idea is that if the loadings are pretty much equal then that’s consistent with the variables all being confounded <em>to the same degree</em> by the same unmeasured thing for both boys and girls. The conventional terrible name for this is ‘Metric’ invariance or ‘Weak’ invariance, but <span class="citation" data-cites="Brown">(<a href="#ref-Brown" role="doc-biblioref"><strong>Brown?</strong></a>)</span> just calls it ‘equal loadings’, which seems fine to me.</p>
<p>We can fit this model in **lavaan* using the <code>cfa()</code> function’s <code>group.equal</code> argument.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>equal.loadings.fit <span class="ot">&lt;-</span> <span class="fu">cfa</span>(onefac, <span class="at">data =</span> dat, <span class="at">group =</span> <span class="st">"female"</span>, </span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">group.equal =</span> <span class="fu">c</span>(<span class="st">"loadings"</span>), <span class="at">meanstructure =</span> <span class="cn">TRUE</span>) </span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(equal.loadings.fit, <span class="at">standardized =</span> <span class="cn">TRUE</span>, <span class="at">fit.measures =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6-12 ended normally after 74 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                        24
  Number of equality constraints                     3

  Number of observations per group:                   
    female                                         109
    male                                            91

Model Test User Model:
                                                      
  Test statistic                                 6.801
  Degrees of freedom                                 7
  P-value (Chi-square)                           0.450
  Test statistic for each group:
    female                                       3.692
    male                                         3.109

Model Test Baseline Model:

  Test statistic                               406.945
  Degrees of freedom                                12
  P-value                                        0.000

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    1.000
  Tucker-Lewis Index (TLI)                       1.001

Loglikelihood and Information Criteria:

  Loglikelihood user model (H0)              -2741.111
  Loglikelihood unrestricted model (H1)      -2737.710
                                                      
  Akaike (AIC)                                5524.221
  Bayesian (BIC)                              5593.486
  Sample-size adjusted Bayesian (BIC)         5526.956

Root Mean Square Error of Approximation:

  RMSEA                                          0.000
  90 Percent confidence interval - lower         0.000
  90 Percent confidence interval - upper         0.121
  P-value RMSEA &lt;= 0.05                          0.612

Standardized Root Mean Square Residual:

  SRMR                                           0.044

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured


Group 1 [female]:

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  f1 =~                                                                 
    read              1.000                               7.844    0.790
    write   (.p2.)    0.866    0.074   11.744    0.000    6.789    0.816
    math    (.p3.)    0.939    0.077   12.214    0.000    7.365    0.836
    science (.p4.)    0.928    0.080   11.590    0.000    7.277    0.790

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .read             51.734    0.951   54.410    0.000   51.734    5.212
   .write            54.991    0.797   69.011    0.000   54.991    6.610
   .math             52.394    0.843   62.128    0.000   52.394    5.951
   .science          50.697    0.882   57.472    0.000   50.697    5.505
    f1                0.000                               0.000    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .read             37.013    6.379    5.802    0.000   37.013    0.376
   .write            23.119    4.238    5.455    0.000   23.119    0.334
   .math             23.282    4.536    5.133    0.000   23.282    0.300
   .science          31.858    5.499    5.794    0.000   31.858    0.376
    f1               61.530   11.526    5.338    0.000    1.000    1.000


Group 2 [male]:

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  f1 =~                                                                 
    read              1.000                               8.664    0.822
    write   (.p2.)    0.866    0.074   11.744    0.000    7.498    0.760
    math    (.p3.)    0.939    0.077   12.214    0.000    8.134    0.803
    science (.p4.)    0.928    0.080   11.590    0.000    8.037    0.775

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .read             52.824    1.105   47.796    0.000   52.824    5.010
   .write            50.121    1.034   48.484    0.000   50.121    5.082
   .math             52.945    1.062   49.862    0.000   52.945    5.227
   .science          53.231    1.088   48.942    0.000   53.231    5.130
    f1                0.000                               0.000    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .read             36.095    7.641    4.724    0.000   36.095    0.325
   .write            41.025    7.538    5.442    0.000   41.025    0.422
   .math             36.439    7.293    4.996    0.000   36.439    0.355
   .science          43.048    8.114    5.305    0.000   43.048    0.400
    f1               75.057   14.697    5.107    0.000    1.000    1.000</code></pre>
</div>
</div>
<p>Notice how in this output the unstandardized loadings are the same in each group, except for the loading for the first variable, which we sacrificed to define the scale of the factor like we usually do. But notice how the standardized loadings are still different.</p>
<p>The loadings and residual variances still look pretty good in this model, but let’s do the likelihood ratio test to see if people will believe me when I tell them I have solid ‘metric’ invariance</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(configural.fit, equal.loadings.fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Chi-Squared Difference Test

                   Df    AIC    BIC Chisq Chisq diff Df diff Pr(&gt;Chisq)
configural.fit      4 5526.0 5605.2 2.622                              
equal.loadings.fit  7 5524.2 5593.5 6.801      4.179       3     0.2428</code></pre>
</div>
</div>
<p>That p-value isn’t significant, so we’re off to the races. So far so good.</p>
</section>
<section id="scalar-strong-invariance" class="level4" data-number="2.1.1.3">
<h4 data-number="2.1.1.3" class="anchored" data-anchor-id="scalar-strong-invariance"><span class="header-section-number">2.1.1.3</span> ‘Scalar’ / ‘Strong’ Invariance</h4>
<p>Moving on now to test whether the goodness of fit is still ok when we constrain the variable-level <em>means</em> to be equal:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>equal.intercepts.fit <span class="ot">&lt;-</span> <span class="fu">cfa</span>(onefac, <span class="at">data =</span> dat, <span class="at">group =</span> <span class="st">"female"</span>, </span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>                            <span class="at">group.equal =</span> <span class="fu">c</span>(<span class="st">"loadings"</span>,<span class="st">"intercepts"</span>), <span class="at">meanstructure =</span> <span class="cn">TRUE</span>)</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(equal.intercepts.fit, <span class="at">standardized =</span> <span class="cn">TRUE</span>, <span class="at">fit.measures =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6-12 ended normally after 108 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                        25
  Number of equality constraints                     7

  Number of observations per group:                   
    female                                         109
    male                                            91

Model Test User Model:
                                                      
  Test statistic                                47.779
  Degrees of freedom                                10
  P-value (Chi-square)                           0.000
  Test statistic for each group:
    female                                      14.313
    male                                        33.466

Model Test Baseline Model:

  Test statistic                               406.945
  Degrees of freedom                                12
  P-value                                        0.000

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    0.904
  Tucker-Lewis Index (TLI)                       0.885

Loglikelihood and Information Criteria:

  Loglikelihood user model (H0)              -2761.600
  Loglikelihood unrestricted model (H1)      -2737.710
                                                      
  Akaike (AIC)                                5559.200
  Bayesian (BIC)                              5618.569
  Sample-size adjusted Bayesian (BIC)         5561.543

Root Mean Square Error of Approximation:

  RMSEA                                          0.194
  90 Percent confidence interval - lower         0.141
  90 Percent confidence interval - upper         0.251
  P-value RMSEA &lt;= 0.05                          0.000

Standardized Root Mean Square Residual:

  SRMR                                           0.089

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured


Group 1 [female]:

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  f1 =~                                                                 
    read              1.000                               7.961    0.797
    write   (.p2.)    0.828    0.076   10.884    0.000    6.592    0.788
    math    (.p3.)    0.940    0.077   12.151    0.000    7.479    0.846
    science (.p4.)    0.915    0.081   11.318    0.000    7.288    0.784

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .read    (.10.)   52.164    0.898   58.065    0.000   52.164    5.224
   .write   (.11.)   53.633    0.766   70.021    0.000   53.633    6.412
   .math    (.12.)   52.534    0.818   64.187    0.000   52.534    5.941
   .science (.13.)   51.595    0.839   61.520    0.000   51.595    5.552
    f1                0.000                               0.000    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .read             36.315    6.399    5.675    0.000   36.315    0.364
   .write            26.507    4.602    5.759    0.000   26.507    0.379
   .math             22.251    4.545    4.896    0.000   22.251    0.285
   .science          33.247    5.715    5.818    0.000   33.247    0.385
    f1               63.376   11.894    5.328    0.000    1.000    1.000


Group 2 [male]:

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  f1 =~                                                                 
    read              1.000                               8.640    0.822
    write   (.p2.)    0.828    0.076   10.884    0.000    7.155    0.681
    math    (.p3.)    0.940    0.077   12.151    0.000    8.117    0.804
    science (.p4.)    0.915    0.081   11.318    0.000    7.910    0.758

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .read    (.10.)   52.164    0.898   58.065    0.000   52.164    4.964
   .write   (.11.)   53.633    0.766   70.021    0.000   53.633    5.103
   .math    (.12.)   52.534    0.818   64.187    0.000   52.534    5.206
   .science (.13.)   51.595    0.839   61.520    0.000   51.595    4.945
    f1                0.152    1.272    0.119    0.905    0.018    0.018

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .read             35.798    7.935    4.512    0.000   35.798    0.324
   .write            59.273   10.111    5.862    0.000   59.273    0.537
   .math             35.924    7.495    4.793    0.000   35.924    0.353
   .science          46.310    8.702    5.322    0.000   46.310    0.425
    f1               74.649   14.704    5.077    0.000    1.000    1.000</code></pre>
</div>
</div>
<p>Yup, as expected, each variable mean is constrained to be the same across groups. And how about that likelihood ratio test?</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(configural.fit, equal.loadings.fit, equal.intercepts.fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Chi-Squared Difference Test

                     Df    AIC    BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)    
configural.fit        4 5526.0 5605.2  2.622                                  
equal.loadings.fit    7 5524.2 5593.5  6.801      4.179       3     0.2428    
equal.intercepts.fit 10 5559.2 5618.6 47.779     40.978       3  6.609e-09 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>Oh no! The p-value is highly significant, so nobody will believe me if I tell them I have ‘strong’ invariance. In other words, my data are consistent with the possibility that even though the variables all load on the factor to the same extent across groups, they still have different values at the same level of each variable. Going back to our primordial DAG of simple confounding, I think this is just another way of saying that the data are consistent with there being secret confounders influencing the variables in one group but not the other. So nobody is gonna believe my DAG.</p>
<p>This opens the door to what <span class="citation" data-cites="Brown">(<a href="#ref-Brown" role="doc-biblioref"><strong>Brown?</strong></a>)</span> calls ‘Partial Invariance’. He encourages us to look at modification indexes like we saw in Example 2 above, and see if freeing up a couple of the fixed parameters would improve goodness of fit. He says this is a fine thing to do, while exposing us to the ever-present risk of noise-mining. As he puts it:</p>
<blockquote class="blockquote">
<p>“[Once you’ve freed a parameter from needing to be equal across groups and the LRT no longer returns a significant p-value], the invariance evaluation may proceed [in accordance with the usual workflow]. The researcher will freely estimate the [now free parameter] in both groups in subsequent [steps of the usual analysis]. Indeed, Byrne et al.&nbsp;(1989) note that such analyses may proceed as long as there exists at least one noninvariant parameter other than the marker indicator”.</p>
</blockquote>
<p>Personally yeah this seems like noise-mining, but let’s give it a try just for fun.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="fu">modindices</span>(equal.intercepts.fit, <span class="at">sort =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Arrange them in order of modification index</span></span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(mi)) <span class="sc">%&gt;%</span> </span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(lhs, op, rhs, mi)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     lhs op     rhs    mi
1   read ~~    math 3.396
2   read ~~    math 2.805
3   read ~~ science 1.670
4   read ~~ science 0.741
5   read ~~   write 0.585
6  write ~~    math 0.497
7  write ~~ science 0.375
8  write ~~ science 0.240
9   read ~~   write 0.210
10  math ~~ science 0.154
11 write ~~    math 0.085
12    f1 =~    read 0.024
13    f1 =~    read 0.024
14  math ~~ science 0.007</code></pre>
</div>
</div>
<p>Hmm, looks like our old friend <code>modindices()</code> doesn’t return estimates for parameters constrained to be equal across groups. But it is showing some interesting stuff. Like maybe instead of freeing up a group-constrained parameter, I could just free up that reading &lt;–&gt; math residual correlation. It feels like a real education researcher could whip up a path diagram that makes this seem justified, and I just tested it and it makes it so that the measurement invariance actually works for the intercepts, even when they are still constrained across groups! So maybe I would just proceed that way.</p>
<p>But just for posterity, here’s how you can look at the modification indexes for the group-constrained parameters:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lavTestScore</span>(equal.intercepts.fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$test

total score test:

   test     X2 df p.value
1 score 40.018  7       0

$uni

univariate score tests:

    lhs op   rhs     X2 df p.value
1  .p2. == .p16.  0.766  1   0.381
2  .p3. == .p17.  2.674  1   0.102
3  .p4. == .p18.  1.308  1   0.253
4 .p10. == .p24.  1.722  1   0.189
5 .p11. == .p25. 33.415  1   0.000
6 .p12. == .p26.  0.407  1   0.524
7 .p13. == .p27.  9.051  1   0.003</code></pre>
</div>
</div>
<p>Annoyingly, it doesn’t tell you the variable names. So you’ll need to check and see what they are called in the model output. Also I think these aren’t technically ‘modification indexes’ per se, but they are analogoes.</p>
<p>Looks like that .p11 == .p25 constraint is a juicy one to free up – this corresponds to the reading variable. To free it up I’ll need to refit the model with more explicit syntax:</p>
<div class="cell">

</div>
<p>I actually think that to do this I would need to respecify the model</p>
</section>
</section>
</section>
<section id="example-5-longitudinal-measurement-invariance" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="example-5-longitudinal-measurement-invariance"><span class="header-section-number">2.2</span> Example 5: Longitudinal Measurement Invariance</h2>
<p>Also do a longitudinal measurement invariance model, since this is what OLES is. Maybe simulate it? Load the data:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">'data/ucla/hsbdemo.csv'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Rows: 200 Columns: 13
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
chr (5): female, ses, schtyp, prog, honors
dbl (8): id, read, write, math, science, socst, awards, cid

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
</div>
</div>
<p>Lastly, let’s walk through <a href="https://www.lavaan.ugent.be/tutorial/cfa.html">an example from the lavaan documentation</a></p>
</section>
<section id="session-info" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="session-info"><span class="header-section-number">2.3</span> Session Info</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sessionInfo</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>R version 4.2.1 (2022-06-23 ucrt)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 19044)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.utf8 
[2] LC_CTYPE=English_United States.utf8   
[3] LC_MONETARY=English_United States.utf8
[4] LC_NUMERIC=C                          
[5] LC_TIME=English_United States.utf8    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] ggdag_0.2.7     lavaan_0.6-12   forcats_0.5.1   stringr_1.4.1  
 [5] dplyr_1.0.9     purrr_0.3.4     readr_2.1.3     tidyr_1.2.0    
 [9] tibble_3.1.8    ggplot2_3.3.6   tidyverse_1.3.2

loaded via a namespace (and not attached):
  [1] readxl_1.4.0        backports_1.4.1     Hmisc_4.7-1        
  [4] semPlot_1.1.6       plyr_1.8.7          igraph_1.3.5       
  [7] splines_4.2.1       digest_0.6.29       htmltools_0.5.3    
 [10] viridis_0.6.2       fansi_1.0.3         magrittr_2.0.3     
 [13] checkmate_2.1.0     googlesheets4_1.0.0 lisrelToR_0.1.5    
 [16] cluster_2.1.3       tzdb_0.3.0          openxlsx_4.2.5     
 [19] graphlayouts_0.8.3  modelr_0.1.8        RcppParallel_5.1.5 
 [22] vroom_1.6.0         jpeg_0.1-9          sem_3.1-15         
 [25] colorspace_2.0-3    rvest_1.0.3         ggrepel_0.9.1      
 [28] haven_2.5.0         xfun_0.32           crayon_1.5.2       
 [31] jsonlite_1.8.3      lme4_1.1-30         survival_3.3-1     
 [34] glue_1.6.2          polyclip_1.10-4     gtable_0.3.1       
 [37] gargle_1.2.0        mi_1.1              V8_4.2.2           
 [40] abind_1.4-5         scales_1.2.1        DBI_1.1.3          
 [43] Rcpp_1.0.9          viridisLite_0.4.1   xtable_1.8-4       
 [46] htmlTable_2.4.1     bit_4.0.4           foreign_0.8-82     
 [49] Formula_1.2-4       stats4_4.2.1        htmlwidgets_1.5.4  
 [52] httr_1.4.4          RColorBrewer_1.1-3  ellipsis_0.3.2     
 [55] pkgconfig_2.0.3     XML_3.99-0.10       farver_2.1.1       
 [58] nnet_7.3-17         kutils_1.70         dbplyr_2.2.1       
 [61] deldir_1.0-6        janitor_2.1.0       utf8_1.2.2         
 [64] reshape2_1.4.4      tidyselect_1.2.0    labeling_0.4.2     
 [67] rlang_1.0.6         munsell_0.5.0       dagitty_0.3-1      
 [70] cellranger_1.1.0    tools_4.2.1         cli_3.3.0          
 [73] generics_0.1.3      broom_1.0.0         fdrtool_1.2.17     
 [76] evaluate_0.17       fastmap_1.1.0       arm_1.13-1         
 [79] yaml_2.3.5          bit64_4.0.5         knitr_1.40         
 [82] fs_1.5.2            tidygraph_1.2.2     zip_2.2.0          
 [85] ggraph_2.1.0        glasso_1.11         pbapply_1.5-0      
 [88] nlme_3.1-157        xml2_1.3.3          compiler_4.2.1     
 [91] rstudioapi_0.14     curl_4.3.2          png_0.1-7          
 [94] reprex_2.0.1        tweenr_2.0.2        pbivnorm_0.6.0     
 [97] stringi_1.7.8       highr_0.9           qgraph_1.9.2       
[100] rockchalk_1.8.157   lattice_0.20-45     Matrix_1.5-1       
[103] psych_2.2.9         nloptr_2.0.3        vctrs_0.4.1        
[106] pillar_1.8.1        lifecycle_1.0.3     OpenMx_2.20.6      
[109] data.table_1.14.2   corpcor_1.6.10      R6_2.5.1           
[112] latticeExtra_0.6-30 gridExtra_2.3       gtools_3.9.3       
[115] boot_1.3-28         MASS_7.3-57         assertthat_0.2.1   
[118] withr_2.5.0         mnormt_2.1.1        parallel_4.2.1     
[121] hms_1.1.2           grid_4.2.1          rpart_4.1.16       
[124] coda_0.19-4         minqa_1.2.5         snakecase_0.11.0   
[127] rmarkdown_2.17      carData_3.0-5       googledrive_2.0.0  
[130] ggforce_0.4.1       semTools_0.5-6      lubridate_1.8.0    
[133] base64enc_0.1-3     interp_1.1-3       </code></pre>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-Green-et-al-1993" class="csl-entry" role="doc-biblioentry">
al, Green et. n.d. <span>“Measurement Error Masks Bipolarity in Affect Ratings.”</span> <em>Journal of Personality and Social Psychology</em> 64(6).
</div>
<div id="ref-Brown2006" class="csl-entry" role="doc-biblioentry">
Brown, Timothy A. 2006. <em>Confirmatory Factor Analysis for Applied Research</em>.
</div>
<div id="ref-Finch2015" class="csl-entry" role="doc-biblioentry">
Finch, French, W. Holmes. 2015. <em>Latent Variable Modeling with r</em>.
</div>
<div id="ref-gorsuch1983" class="csl-entry" role="doc-biblioentry">
Gorsuch, Richard L. 1983. <em>Factor Analysis, 2nd Edition</em>.
</div>
<div id="ref-Kline2011" class="csl-entry" role="doc-biblioentry">
Kline, Rex B. 2011. <em>Principles and Practice of Structural Equation Modeling</em>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./intro.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./sem.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">SEM</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>