<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Latent Variable Modelling Workflow Reference - 4&nbsp; MTMM and Error Structure Modelling</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./sem.html" rel="next">
<link href="./mtmm-and-error-structure-modelling.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">MTMM and Error Structure Modelling</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Latent Variable Modelling Workflow Reference</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./cfa-intro.html" class="sidebar-item-text sidebar-link">The Whole Game</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./traditional-cfa-workflow.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Traditional CFA Workflow</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./modification-indexes.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Modification Indexes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mtmm-and-error-structure-modelling.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">MTMM and Error Structure Modelling</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./measurement-invariance-testing.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">MTMM and Error Structure Modelling</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./sem.html" class="sidebar-item-text sidebar-link">SEM</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./latent-variable-regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Regression with Latent Variables</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#example-4-school-grades" id="toc-example-4-school-grades" class="nav-link active" data-scroll-target="#example-4-school-grades">Example 4: School Grades</a>
  <ul class="collapse">
  <li><a href="#measurement-invariance" id="toc-measurement-invariance" class="nav-link" data-scroll-target="#measurement-invariance">Measurement Invariance</a></li>
  <li><a href="#multigroup-cfa" id="toc-multigroup-cfa" class="nav-link" data-scroll-target="#multigroup-cfa">Multigroup CFA</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">MTMM and Error Structure Modelling</span></h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<p>In this chapter we’ll work through another example of the Traditional CFA Workflow to get more practice. We’ll also introduce the concept of ‘Modification Indexes’, which researchers often use to improve their model goodness of fit in a way that seems a bit suss to me. Probably a good thing to know about.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lavaan)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggdag)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="example-4-school-grades" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="example-4-school-grades">Example 4: School Grades</h2>
<p>Now let’s do <a href="https://stats.oarc.ucla.edu/r/seminars/lgm/">an example taken from the Advanced Statistical Computing people at UCLA</a>. The dataset comes from the High School and Beyond project, which tracks academic performance in the US along with some data about students.</p>
<p>As usual with CFA, my goal here is to convince somebody that some of my variables are confounded by a shared unmeasured (and unmeasurable) variable, and not by other unmeasured things in different ways from each other. Specifically, I want to convince you that four student grades, namely reading, writing, mathematics and science, are confounded by a shared unmeasurable variable called ‘academic performance’. Great.</p>
<section id="measurement-invariance" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="measurement-invariance">Measurement Invariance</h3>
<p>But there’s a problem: a reviewer might ask if it really makes sense to think of ‘academic performance’ as being the same thing for boy-labelled and girl-labelled people. So if I want to convince that reviewer of my usual ‘simple confounding’ DAG structure, then I’ll need to answer a few extra questions:</p>
<ol type="1">
<li>Does the model fit equally well when I fit it on the group-level sub-datasets in isolation?</li>
<li>Are the data consistent with the idea that the different groups are actually confounded by the same latent thing? People like to test this by making sure the loadings are pretty similar across the models for the different groups. If the loadings are similar then I can can say they are ‘invariant’.</li>
<li>Do the data themselves actually have stable properties across groups? If not, then even if the model fits the data equally well for different groups or at different times, and even if the loadings are pretty similar across groups, then that’s actually a bad thing if I want to convince you that the factor is the same thing for different groups! People generally just like to check this by including an intercept term in the linear regression for each variable in the CFA model. If these intercepts are pretty similar across groups or across timepoints then we can say they are ‘invariant’.</li>
</ol>
<p>When I’m worrying about these sorts of things, I am worrying about what people like to call <strong>measurement invariance.</strong> As <span class="citation" data-cites="Brown2006">Brown (<a href="#ref-Brown2006" role="doc-biblioref">2006</a>)</span> puts it, the big idea with ‘Measurement Invariance’ is the worry that:</p>
<blockquote class="blockquote">
<p>“if either the loading or the intercept [of a variable across groups] is noninvariant, [then the model thinks] the observed values of the indicator will differ between groups at a given level of the latent variable.”</p>
</blockquote>
<p>We definitely don’t want a model that thinks that, because it is not consistent with what I’m trying to convince my reviewers of: that the observed variables are merely puppets, confounded by the same unmeasured variable in the same way across all groups or timepoints.</p>
</section>
<section id="multigroup-cfa" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="multigroup-cfa">Multigroup CFA</h3>
<p>There are a few classical workflows for dealing with measurement invariance, which @Brown2006 details in chapter 7 of his book. But he recommends something called ‘Multigroup CFA’, so let’s go with that. We’ll be following the workflow for this type of model as presented in that chapter.</p>
<section id="configural-invariance" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="configural-invariance">‘Configural’ Invariance</h4>
<p>The first step is to fit the model separately for the two groups in isolation and see whether they both have OK goodness of fit. So let’s split the data into two subsets based on the group we’re interested in, and then define the <strong>lavaan</strong> models with the usual syntax, but specifying that want the linear model of each variable to also have an intercept, as explained above:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="do">### Load the data</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">'../data/ucla/hsbdemo.csv'</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="do">### Load the data again but in split format, for what is to come.</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>dat_split <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">boys  =</span> dat <span class="sc">%&gt;%</span> <span class="fu">filter</span>(female <span class="sc">==</span> <span class="st">"female"</span>),</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">girls =</span> dat <span class="sc">%&gt;%</span> <span class="fu">filter</span>(female <span class="sc">==</span> <span class="st">"male"</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="do">### Define the basic CFA model</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>onefac <span class="ot">&lt;-</span> <span class="st">'f1  =~ read + write + math + science'</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="do">### Fit the model separately for each group</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>onefac_models <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">onefac_boys  =</span> <span class="fu">cfa</span>(onefac, <span class="at">data =</span> dat_split<span class="sc">$</span>boys, <span class="at">meanstructure =</span> <span class="cn">TRUE</span>),</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">onefac_girls =</span> <span class="fu">cfa</span>(onefac, <span class="at">data =</span> dat_split<span class="sc">$</span>girls, <span class="at">meanstructure =</span> <span class="cn">TRUE</span>) </span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="do">### Gaze at the parameter estimates</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>onefac_models <span class="sc">%&gt;%</span> <span class="fu">map</span>(summary, <span class="at">standardized =</span> <span class="cn">TRUE</span>, <span class="at">fit.measures =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$onefac_boys
lavaan 0.6.16 ended normally after 46 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                        12

  Number of observations                           109

Model Test User Model:
                                                      
  Test statistic                                 1.903
  Degrees of freedom                                 2
  P-value (Chi-square)                           0.386

Model Test Baseline Model:

  Test statistic                               230.890
  Degrees of freedom                                 6
  P-value                                        0.000

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    1.000
  Tucker-Lewis Index (TLI)                       1.001

Loglikelihood and Information Criteria:

  Loglikelihood user model (H0)              -1463.504
  Loglikelihood unrestricted model (H1)      -1462.553
                                                      
  Akaike (AIC)                                2951.009
  Bayesian (BIC)                              2983.305
  Sample-size adjusted Bayesian (SABIC)       2945.387

Root Mean Square Error of Approximation:

  RMSEA                                          0.000
  90 Percent confidence interval - lower         0.000
  90 Percent confidence interval - upper         0.187
  P-value H_0: RMSEA &lt;= 0.050                    0.479
  P-value H_0: RMSEA &gt;= 0.080                    0.400

Standardized Root Mean Square Residual:

  SRMR                                           0.013

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  f1 =~                                                                 
    read              1.000                               8.006    0.800
    write             0.801    0.091    8.769    0.000    6.414    0.792
    math              0.985    0.102    9.621    0.000    7.889    0.866
    science           0.863    0.102    8.453    0.000    6.912    0.768

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .read             51.734    0.959   53.949    0.000   51.734    5.167
   .write            54.991    0.775   70.911    0.000   54.991    6.792
   .math             52.394    0.872   60.052    0.000   52.394    5.752
   .science          50.697    0.862   58.830    0.000   50.697    5.635
    f1                0.000                               0.000    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .read             36.133    6.426    5.623    0.000   36.133    0.360
   .write            24.410    4.271    5.716    0.000   24.410    0.372
   .math             20.736    4.693    4.419    0.000   20.736    0.250
   .science          33.165    5.555    5.971    0.000   33.165    0.410
    f1               64.099   13.331    4.808    0.000    1.000    1.000


$onefac_girls
lavaan 0.6.16 ended normally after 44 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                        12

  Number of observations                            91

Model Test User Model:
                                                      
  Test statistic                                 0.719
  Degrees of freedom                                 2
  P-value (Chi-square)                           0.698

Model Test Baseline Model:

  Test statistic                               176.055
  Degrees of freedom                                 6
  P-value                                        0.000

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    1.000
  Tucker-Lewis Index (TLI)                       1.023

Loglikelihood and Information Criteria:

  Loglikelihood user model (H0)              -1275.517
  Loglikelihood unrestricted model (H1)      -1275.157
                                                      
  Akaike (AIC)                                2575.033
  Bayesian (BIC)                              2605.164
  Sample-size adjusted Bayesian (SABIC)       2567.288

Root Mean Square Error of Approximation:

  RMSEA                                          0.000
  90 Percent confidence interval - lower         0.000
  90 Percent confidence interval - upper         0.153
  P-value H_0: RMSEA &lt;= 0.050                    0.750
  P-value H_0: RMSEA &gt;= 0.080                    0.186

Standardized Root Mean Square Residual:

  SRMR                                           0.009

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  f1 =~                                                                 
    read              1.000                               8.531    0.816
    write             0.954    0.119    7.983    0.000    8.137    0.794
    math              0.863    0.113    7.663    0.000    7.361    0.766
    science           0.999    0.124    8.031    0.000    8.521    0.798

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .read             52.824    1.095   48.227    0.000   52.824    5.056
   .write            50.121    1.074   46.653    0.000   50.121    4.891
   .math             52.945    1.008   52.548    0.000   52.945    5.508
   .science          53.231    1.119   47.577    0.000   53.231    4.987
    f1                0.000                               0.000    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .read             36.404    7.769    4.686    0.000   36.404    0.333
   .write            38.825    7.775    4.993    0.000   38.825    0.370
   .math             38.197    7.210    5.298    0.000   38.197    0.413
   .science          41.300    8.365    4.937    0.000   41.300    0.363
    f1               72.774   16.251    4.478    0.000    1.000    1.000</code></pre>
</div>
</div>
<p>The first thing I notice is that the models don’t fit great. Indeed, these are the first significant chi-squared test p-values I’ve ever seen in all of these examples, indicating that the results are consistent with there being lots of residual variance the model hasn’t accounted for. But the UCLA people don’t comment on this, so I guess neither will I.</p>
<p>Next I notice that the factor loadings and residual variances look pretty good and consistent across the groups. This is suggestive of what people unfortunately like to call <strong>Configural Invariance</strong>, which just means the same model fits to the groups pretty much the same in isolation. As <span class="citation" data-cites="Brown">(<a href="#ref-Brown" role="doc-biblioref"><strong>Brown?</strong></a>)</span> puts it:</p>
<blockquote class="blockquote">
<p>“equal form [aka ‘configural invariance’ is when] the number of factors and pattern of indicator–factor loadings are identical across groups)”</p>
</blockquote>
<p>The main exception to this I notice in the above model is that there’s a bunch more residual variance in ‘math’ for boys than for girls. So maybe that’s something to look out for.</p>
<p>The next thing to do is fit the exact same model as above, but in a slightly fancier syntax. Specifically, we’re gonna fit it with a single command so that it can serve as the best-fitting big daddy model when we start constraining parameters to be equal across groups and doing the nested likelihood ratio test stuff we’ll be doing later. I think this is literally the exact same thing as the previous model but it serves that LRT-daddy role by giving us a single chi-squared goodness-of-fit statistic for the whole dataset, rather than one for each group in isolation. Honestly I’m not sure why both <span class="citation" data-cites="Brown">(<a href="#ref-Brown" role="doc-biblioref"><strong>Brown?</strong></a>)</span> and UCLA have us fit the previous model at all.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>configural.fit <span class="ot">&lt;-</span> <span class="fu">cfa</span>(onefac, <span class="at">data =</span> dat, <span class="at">group =</span> <span class="st">"female"</span>, <span class="at">meanstructure =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Notice how we just did the exact same thing as before, but we used the full dataset instead of the split sub-datasets, and we used <code>cfa()</code> function’s <code>group</code> parameter to tell the model we’re interested in group stuff. I’m not actually gonna print the outputs for this model because the loadings and residual variances are the exact same for the previous model, and the single chi-squared statistic is simply the sum of the chi-squared statistics from the previous model.</p>
</section>
<section id="metric-weak-invariance" class="level4" data-number="4.0.0.1">
<h4 data-number="4.0.0.1" class="anchored" data-anchor-id="metric-weak-invariance"><span class="header-section-number">4.0.0.1</span> ‘Metric’ / ‘Weak’ Invariance</h4>
<p>Next we’re gonna want to see if goodness-of-fit isn’t significantly reduced when we constrain the loading for each variable to be equal in both models. The idea is that if the loadings are pretty much equal then that’s consistent with the variables all being confounded <em>to the same degree</em> by the same unmeasured thing for both boys and girls. The conventional terrible name for this is ‘Metric’ invariance or ‘Weak’ invariance, but <span class="citation" data-cites="Brown">(<a href="#ref-Brown" role="doc-biblioref"><strong>Brown?</strong></a>)</span> just calls it ‘equal loadings’, which seems fine to me.</p>
<p>We can fit this model in **lavaan* using the <code>cfa()</code> function’s <code>group.equal</code> argument.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>equal.loadings.fit <span class="ot">&lt;-</span> <span class="fu">cfa</span>(onefac, <span class="at">data =</span> dat, <span class="at">group =</span> <span class="st">"female"</span>, </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">group.equal =</span> <span class="fu">c</span>(<span class="st">"loadings"</span>), <span class="at">meanstructure =</span> <span class="cn">TRUE</span>) </span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(equal.loadings.fit, <span class="at">standardized =</span> <span class="cn">TRUE</span>, <span class="at">fit.measures =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6.16 ended normally after 74 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                        24
  Number of equality constraints                     3

  Number of observations per group:                   
    female                                         109
    male                                            91

Model Test User Model:
                                                      
  Test statistic                                 6.801
  Degrees of freedom                                 7
  P-value (Chi-square)                           0.450
  Test statistic for each group:
    female                                       3.692
    male                                         3.109

Model Test Baseline Model:

  Test statistic                               406.945
  Degrees of freedom                                12
  P-value                                        0.000

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    1.000
  Tucker-Lewis Index (TLI)                       1.001

Loglikelihood and Information Criteria:

  Loglikelihood user model (H0)              -2741.111
  Loglikelihood unrestricted model (H1)      -2737.710
                                                      
  Akaike (AIC)                                5524.221
  Bayesian (BIC)                              5593.486
  Sample-size adjusted Bayesian (SABIC)       5526.956

Root Mean Square Error of Approximation:

  RMSEA                                          0.000
  90 Percent confidence interval - lower         0.000
  90 Percent confidence interval - upper         0.121
  P-value H_0: RMSEA &lt;= 0.050                    0.612
  P-value H_0: RMSEA &gt;= 0.080                    0.212

Standardized Root Mean Square Residual:

  SRMR                                           0.044

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured


Group 1 [female]:

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  f1 =~                                                                 
    read              1.000                               7.844    0.790
    write   (.p2.)    0.866    0.074   11.744    0.000    6.789    0.816
    math    (.p3.)    0.939    0.077   12.214    0.000    7.365    0.836
    science (.p4.)    0.928    0.080   11.590    0.000    7.277    0.790

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .read             51.734    0.951   54.410    0.000   51.734    5.212
   .write            54.991    0.797   69.011    0.000   54.991    6.610
   .math             52.394    0.843   62.128    0.000   52.394    5.951
   .science          50.697    0.882   57.472    0.000   50.697    5.505
    f1                0.000                               0.000    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .read             37.013    6.379    5.802    0.000   37.013    0.376
   .write            23.119    4.238    5.455    0.000   23.119    0.334
   .math             23.282    4.536    5.133    0.000   23.282    0.300
   .science          31.858    5.499    5.794    0.000   31.858    0.376
    f1               61.530   11.526    5.338    0.000    1.000    1.000


Group 2 [male]:

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  f1 =~                                                                 
    read              1.000                               8.664    0.822
    write   (.p2.)    0.866    0.074   11.744    0.000    7.498    0.760
    math    (.p3.)    0.939    0.077   12.214    0.000    8.134    0.803
    science (.p4.)    0.928    0.080   11.590    0.000    8.037    0.775

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .read             52.824    1.105   47.796    0.000   52.824    5.010
   .write            50.121    1.034   48.484    0.000   50.121    5.082
   .math             52.945    1.062   49.862    0.000   52.945    5.227
   .science          53.231    1.088   48.942    0.000   53.231    5.130
    f1                0.000                               0.000    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .read             36.095    7.641    4.724    0.000   36.095    0.325
   .write            41.025    7.538    5.442    0.000   41.025    0.422
   .math             36.439    7.293    4.996    0.000   36.439    0.355
   .science          43.048    8.114    5.305    0.000   43.048    0.400
    f1               75.057   14.697    5.107    0.000    1.000    1.000</code></pre>
</div>
</div>
<p>Notice how in this output the unstandardized loadings are the same in each group, except for the loading for the first variable, which we sacrificed to define the scale of the factor like we usually do. But notice how the standardized loadings are still different.</p>
<p>The loadings and residual variances still look pretty good in this model, but let’s do the likelihood ratio test to see if people will believe me when I tell them I have solid ‘metric’ invariance</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(configural.fit, equal.loadings.fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Chi-Squared Difference Test

                   Df    AIC    BIC Chisq Chisq diff   RMSEA Df diff Pr(&gt;Chisq)
configural.fit      4 5526.0 5605.2 2.622                                      
equal.loadings.fit  7 5524.2 5593.5 6.801      4.179 0.06269       3     0.2428</code></pre>
</div>
</div>
<p>That p-value isn’t significant, so we’re off to the races. So far so good.</p>
</section>
<section id="scalar-strong-invariance" class="level4" data-number="4.0.0.2">
<h4 data-number="4.0.0.2" class="anchored" data-anchor-id="scalar-strong-invariance"><span class="header-section-number">4.0.0.2</span> ‘Scalar’ / ‘Strong’ Invariance</h4>
<p>Moving on now to test whether the goodness of fit is still ok when we constrain the variable-level <em>means</em> to be equal:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>equal.intercepts.fit <span class="ot">&lt;-</span> <span class="fu">cfa</span>(onefac, <span class="at">data =</span> dat, <span class="at">group =</span> <span class="st">"female"</span>, </span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>                            <span class="at">group.equal =</span> <span class="fu">c</span>(<span class="st">"loadings"</span>,<span class="st">"intercepts"</span>), <span class="at">meanstructure =</span> <span class="cn">TRUE</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(equal.intercepts.fit, <span class="at">standardized =</span> <span class="cn">TRUE</span>, <span class="at">fit.measures =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>lavaan 0.6.16 ended normally after 108 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                        25
  Number of equality constraints                     7

  Number of observations per group:                   
    female                                         109
    male                                            91

Model Test User Model:
                                                      
  Test statistic                                47.779
  Degrees of freedom                                10
  P-value (Chi-square)                           0.000
  Test statistic for each group:
    female                                      14.313
    male                                        33.466

Model Test Baseline Model:

  Test statistic                               406.945
  Degrees of freedom                                12
  P-value                                        0.000

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    0.904
  Tucker-Lewis Index (TLI)                       0.885

Loglikelihood and Information Criteria:

  Loglikelihood user model (H0)              -2761.600
  Loglikelihood unrestricted model (H1)      -2737.710
                                                      
  Akaike (AIC)                                5559.200
  Bayesian (BIC)                              5618.569
  Sample-size adjusted Bayesian (SABIC)       5561.543

Root Mean Square Error of Approximation:

  RMSEA                                          0.194
  90 Percent confidence interval - lower         0.141
  90 Percent confidence interval - upper         0.251
  P-value H_0: RMSEA &lt;= 0.050                    0.000
  P-value H_0: RMSEA &gt;= 0.080                    1.000

Standardized Root Mean Square Residual:

  SRMR                                           0.089

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured


Group 1 [female]:

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  f1 =~                                                                 
    read              1.000                               7.961    0.797
    write   (.p2.)    0.828    0.076   10.884    0.000    6.592    0.788
    math    (.p3.)    0.940    0.077   12.151    0.000    7.479    0.846
    science (.p4.)    0.915    0.081   11.318    0.000    7.288    0.784

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .read    (.10.)   52.164    0.898   58.065    0.000   52.164    5.224
   .write   (.11.)   53.633    0.766   70.021    0.000   53.633    6.412
   .math    (.12.)   52.534    0.818   64.187    0.000   52.534    5.941
   .science (.13.)   51.595    0.839   61.520    0.000   51.595    5.552
    f1                0.000                               0.000    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .read             36.315    6.399    5.675    0.000   36.315    0.364
   .write            26.507    4.602    5.759    0.000   26.507    0.379
   .math             22.251    4.545    4.896    0.000   22.251    0.285
   .science          33.247    5.715    5.818    0.000   33.247    0.385
    f1               63.376   11.894    5.328    0.000    1.000    1.000


Group 2 [male]:

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  f1 =~                                                                 
    read              1.000                               8.640    0.822
    write   (.p2.)    0.828    0.076   10.884    0.000    7.155    0.681
    math    (.p3.)    0.940    0.077   12.151    0.000    8.117    0.804
    science (.p4.)    0.915    0.081   11.318    0.000    7.910    0.758

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .read    (.10.)   52.164    0.898   58.065    0.000   52.164    4.964
   .write   (.11.)   53.633    0.766   70.021    0.000   53.633    5.103
   .math    (.12.)   52.534    0.818   64.187    0.000   52.534    5.206
   .science (.13.)   51.595    0.839   61.520    0.000   51.595    4.945
    f1                0.152    1.272    0.119    0.905    0.018    0.018

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .read             35.798    7.935    4.512    0.000   35.798    0.324
   .write            59.273   10.111    5.862    0.000   59.273    0.537
   .math             35.924    7.495    4.793    0.000   35.924    0.353
   .science          46.310    8.702    5.322    0.000   46.310    0.425
    f1               74.649   14.704    5.077    0.000    1.000    1.000</code></pre>
</div>
</div>
<p>Yup, as expected, each variable mean is constrained to be the same across groups. And how about that likelihood ratio test?</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(configural.fit, equal.loadings.fit, equal.intercepts.fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Chi-Squared Difference Test

                     Df    AIC    BIC  Chisq Chisq diff   RMSEA Df diff
configural.fit        4 5526.0 5605.2  2.622                           
equal.loadings.fit    7 5524.2 5593.5  6.801      4.179 0.06269       3
equal.intercepts.fit 10 5559.2 5618.6 47.779     40.978 0.35580       3
                     Pr(&gt;Chisq)    
configural.fit                     
equal.loadings.fit       0.2428    
equal.intercepts.fit  6.609e-09 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>Oh no! The p-value is highly significant, so nobody will believe me if I tell them I have ‘strong’ invariance. In other words, my data are consistent with the possibility that even though the variables all load on the factor to the same extent across groups, they still have different values at the same level of each variable. Going back to our primordial DAG of simple confounding, I think this is just another way of saying that the data are consistent with there being secret confounders influencing the variables in one group but not the other. So nobody is gonna believe my DAG.</p>
<p>This opens the door to what <span class="citation" data-cites="Brown">(<a href="#ref-Brown" role="doc-biblioref"><strong>Brown?</strong></a>)</span> calls ‘Partial Invariance’. He encourages us to look at modification indexes like we saw in Example 2 above, and see if freeing up a couple of the fixed parameters would improve goodness of fit. He says this is a fine thing to do, while exposing us to the ever-present risk of noise-mining. As he puts it:</p>
<blockquote class="blockquote">
<p>“[Once you’ve freed a parameter from needing to be equal across groups and the LRT no longer returns a significant p-value], the invariance evaluation may proceed [in accordance with the usual workflow]. The researcher will freely estimate the [now free parameter] in both groups in subsequent [steps of the usual analysis]. Indeed, Byrne et al.&nbsp;(1989) note that such analyses may proceed as long as there exists at least one noninvariant parameter other than the marker indicator”.</p>
</blockquote>
<p>Personally yeah this seems like noise-mining, but let’s give it a try just for fun.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">modindices</span>(equal.intercepts.fit, <span class="at">sort =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Arrange them in order of modification index</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(mi)) <span class="sc">%&gt;%</span> </span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(lhs, op, rhs, mi)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     lhs op     rhs    mi
1   read ~~    math 3.396
2   read ~~    math 2.805
3   read ~~ science 1.670
4   read ~~ science 0.741
5   read ~~   write 0.585
6  write ~~    math 0.497
7  write ~~ science 0.375
8  write ~~ science 0.240
9   read ~~   write 0.210
10  math ~~ science 0.154
11 write ~~    math 0.085
12    f1 =~    read 0.024
13    f1 =~    read 0.024
14  math ~~ science 0.007</code></pre>
</div>
</div>
<p>Hmm, looks like our old friend <code>modindices()</code> doesn’t return estimates for parameters constrained to be equal across groups. But it is showing some interesting stuff. Like maybe instead of freeing up a group-constrained parameter, I could just free up that reading &lt;–&gt; math residual correlation. It feels like a real education researcher could whip up a path diagram that makes this seem justified, and I just tested it and it makes it so that the measurement invariance actually works for the intercepts, even when they are still constrained across groups! So maybe I would just proceed that way.</p>
<p>But just for posterity, here’s how you can look at the modification indexes for the group-constrained parameters:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lavTestScore</span>(equal.intercepts.fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$test

total score test:

   test     X2 df p.value
1 score 40.018  7       0

$uni

univariate score tests:

    lhs op   rhs     X2 df p.value
1  .p2. == .p16.  0.766  1   0.381
2  .p3. == .p17.  2.674  1   0.102
3  .p4. == .p18.  1.308  1   0.253
4 .p10. == .p24.  1.722  1   0.189
5 .p11. == .p25. 33.415  1   0.000
6 .p12. == .p26.  0.407  1   0.524
7 .p13. == .p27.  9.051  1   0.003</code></pre>
</div>
</div>
<p>Annoyingly, it doesn’t tell you the variable names. So you’ll need to check and see what they are called in the model output. Also I think these aren’t technically ‘modification indexes’ per se, but they are analogous.</p>
<p>Looks like that .p11 == .p25 constraint is a juicy one to free up – this corresponds to the reading variable. To free it up I’ll need to refit the model with more explicit syntax. Specifically, I’ll need to use the <code>group.partial()</code> argument to override the fixedness introduced in the <code>group.equal()</code> argument:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="do">### Partial invariance model</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>partial.invariance.fit <span class="ot">&lt;-</span> <span class="fu">cfa</span>(</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>  onefac, </span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>  dat, </span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">group =</span> <span class="st">"female"</span>, </span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">group.equal =</span> <span class="fu">c</span>(<span class="st">"loadings"</span>, <span class="st">"intercepts"</span>), </span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">group.partial=</span><span class="fu">c</span>(<span class="st">"read~1"</span>), <span class="co"># This frees up the desired intercepts</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">meanstructure =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we can re-run the likelihood ratio test and see if we’re good to proceed to testing for invariance of the residual variance terms:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(configural.fit, equal.loadings.fit, partial.invariance.fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Chi-Squared Difference Test

                       Df    AIC    BIC  Chisq Chisq diff   RMSEA Df diff
configural.fit          4 5526.0 5605.2  2.622                           
equal.loadings.fit      7 5524.2 5593.5  6.801      4.179 0.06269       3
partial.invariance.fit  9 5559.3 5622.0 45.885     39.084 0.43060       2
                       Pr(&gt;Chisq)    
configural.fit                       
equal.loadings.fit         0.2428    
partial.invariance.fit  3.259e-09 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>Gah, allowing the intercept to be freely estimated has improved the p-value, but it still looks like the data are consistent with the idea that the observed variables have different values across groups for the same value of the latent variable. Darn! We could keep going, IE checking the modification indexes and freeing up parameters until we pass the likelihood ratio test, but that doesn’t feel so good to me. These data just aren’t consistent with the theory offered by the primordial DAG of simple confounding.</p>


<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-Brown2006" class="csl-entry" role="doc-biblioentry">
Brown, Timothy A. 2006. <em>Confirmatory Factor Analysis for Applied Research</em>.
</div>
</div>
</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./mtmm-and-error-structure-modelling.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">MTMM and Error Structure Modelling</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./sem.html" class="pagination-link">
        <span class="nav-page-text">SEM</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>